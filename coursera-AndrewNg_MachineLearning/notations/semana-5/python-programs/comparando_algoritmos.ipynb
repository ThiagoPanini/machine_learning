{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Preparando-Análise\" data-toc-modified-id=\"Preparando-Análise-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Preparando Análise</a></span></li><li><span><a href=\"#Decision-Trees\" data-toc-modified-id=\"Decision-Trees-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Decision Trees</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dados-de-Treino\" data-toc-modified-id=\"Dados-de-Treino-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Dados de Treino</a></span></li><li><span><a href=\"#Tunando-Hiperparâmetros\" data-toc-modified-id=\"Tunando-Hiperparâmetros-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Tunando Hiperparâmetros</a></span></li><li><span><a href=\"#Dados-de-Teste\" data-toc-modified-id=\"Dados-de-Teste-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Dados de Teste</a></span></li><li><span><a href=\"#Shifting-Images\" data-toc-modified-id=\"Shifting-Images-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Shifting Images</a></span></li></ul></li><li><span><a href=\"#SGD-Classifier\" data-toc-modified-id=\"SGD-Classifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>SGD Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dados-de-Treino\" data-toc-modified-id=\"Dados-de-Treino-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Dados de Treino</a></span></li><li><span><a href=\"#Tunando-Hiperparâmetros\" data-toc-modified-id=\"Tunando-Hiperparâmetros-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Tunando Hiperparâmetros</a></span></li><li><span><a href=\"#Dados-de-Teste\" data-toc-modified-id=\"Dados-de-Teste-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Dados de Teste</a></span></li><li><span><a href=\"#Shifting-Images\" data-toc-modified-id=\"Shifting-Images-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Shifting Images</a></span></li></ul></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dados-de-Treino\" data-toc-modified-id=\"Dados-de-Treino-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Dados de Treino</a></span></li><li><span><a href=\"#Tunando-Hiperparâmetros\" data-toc-modified-id=\"Tunando-Hiperparâmetros-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Tunando Hiperparâmetros</a></span></li><li><span><a href=\"#Dados-de-Teste\" data-toc-modified-id=\"Dados-de-Teste-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Dados de Teste</a></span></li><li><span><a href=\"#Shifting-Images\" data-toc-modified-id=\"Shifting-Images-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Shifting Images</a></span></li></ul></li><li><span><a href=\"#Multi-Layer-Perceptron\" data-toc-modified-id=\"Multi-Layer-Perceptron-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Multi Layer Perceptron</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dados-de-Treino\" data-toc-modified-id=\"Dados-de-Treino-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dados de Treino</a></span></li><li><span><a href=\"#Tunando-Hiperparâmetros\" data-toc-modified-id=\"Tunando-Hiperparâmetros-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Tunando Hiperparâmetros</a></span></li><li><span><a href=\"#Dados-de-Teste\" data-toc-modified-id=\"Dados-de-Teste-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Dados de Teste</a></span></li><li><span><a href=\"#Shifting-Images\" data-toc-modified-id=\"Shifting-Images-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Shifting Images</a></span></li></ul></li><li><span><a href=\"#Conclusão\" data-toc-modified-id=\"Conclusão-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Conclusão</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook tem por objetivo comparar diferentes algoritmos utilizados em problemas de classificação através do dataset MNIST. Com isso, será possível avaliar a performance de cada um deles, avaliando, analisando e identificando importantes parâmetros como tempo de processamento e complexidade dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando Análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:56:50.595158Z",
     "start_time": "2019-01-17T21:56:27.551306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas para análise e preparação dos dados\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from random import randint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "# Importando bibliotecas para treinamento de algoritmos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Importando bibliotecas para avaliação de performance\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:56:51.263560Z",
     "start_time": "2019-01-17T21:56:50.603755Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definindo funções e variáveis\n",
    "\n",
    "def create_dataset():\n",
    "    \"\"\"\n",
    "    Função para criação (primeira vez) de um dataset vazio para armazenar acurácias\n",
    "    \"\"\"\n",
    "    dataset_cols = ['acc_train', 'acc_train_cv', 'acc_train_scaled', 'acc_test'\n",
    "                   ,'acc_test_scaled', 'acc_test_grid', 'acc_test_shifted']\n",
    "    dict_accs = {}\n",
    "    dataset_accs = pd.DataFrame({})\n",
    "    for col in dataset_cols:\n",
    "        dataset_accs[col] = []\n",
    "    return dataset_accs, dict_accs\n",
    "\n",
    "def load_dataset():\n",
    "    \"\"\"\n",
    "    Função responsável por ler dataset já criado (a partir da primeira vez)\n",
    "    \n",
    "    Output:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    path = 'C:/Users/thiagoPanini/data-science-repos/coursera-stanford/'\n",
    "    root = 'machine-learning/notations/semana-5/python-programs/'\n",
    "    file_name = 'dataset_accs.csv'\n",
    "    \n",
    "    return pd.read_csv(path+root+file_name)\n",
    "\n",
    "def save_dataset(df):\n",
    "    \"\"\"\n",
    "    Função responsável por salvar o dataset a partir da primeira análise\n",
    "    \n",
    "    Input:\n",
    "        DataFrame a ser salvo\n",
    "    \"\"\"\n",
    "    df.to_csv('dataset_accs.csv', index=False)\n",
    "    \n",
    "def display_scores(scores):\n",
    "    \"\"\"\n",
    "    Função para mostrar scores da validação cruzada\n",
    "    \"\"\"\n",
    "    print(f'Scores: {scores}')\n",
    "    print(f'Média: {scores.mean():.4f}')\n",
    "    print(f'Desvio Padrão: {scores.std():.4f}')\n",
    "    \n",
    "def prepare_mnist():\n",
    "    \"\"\"\n",
    "    Função responsável por importar e realizar todos os procedimentos preparatórios\n",
    "    no dataset MNIST.\n",
    "    \n",
    "    Output: X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    # Download das bibliotecas necessárias\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    import numpy as np\n",
    "    \n",
    "    # Download e separação do dataset\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    X, y = mnist['data'], mnist['target']\n",
    "    \n",
    "    # Separando dados de treino e de teste\n",
    "    X_train, y_train, X_test, y_test = X[:60000], y[:60000], X[60000:], y[60000:]\n",
    "    \n",
    "    # Embaralhando dados\n",
    "    shuffle_index = np.random.permutation(X_train.shape[0])\n",
    "    X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "    \n",
    "    # Retornando dados\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def data_scaled(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Função responsável por aplicar padronização no conjunto de dados\n",
    "    \n",
    "    Input: X_train, X_test -> dados brutos\n",
    "    Output: X_train_scaled, X_test_scaled -> dados padronizados\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.fit_transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "def shift_image(image, dx, dy):\n",
    "    \"\"\"\n",
    "    Função responsável por deslocar imagens do dataset em determinada direção\n",
    "    \n",
    "    Input: \n",
    "        image (registro do dataset X_train)\n",
    "        dx, dy (deslocamentos em x e y)\n",
    "    Output:\n",
    "        shifted_image (imagem deslocada)\n",
    "    \"\"\"\n",
    "    image = image.reshape((28, 28))\n",
    "    shift_image = shift(image, [dy, dx], cval=0, mode='constant')\n",
    "    return shift_image.reshape([-1])\n",
    "\n",
    "def augment_data(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Função para deslocar imagens do dataset em todas as direções\n",
    "    \n",
    "    Input:\n",
    "        X_train, y_train (dados brutos de entrada)\n",
    "    Output:\n",
    "        X_train_augmented, y_train_augmented (dados deslocados e embaralhados em formato de array)\n",
    "    \"\"\"\n",
    "    X_train_augmented = [image for image in X_train]\n",
    "    y_train_augmented = [label for label in y_train]\n",
    "    \n",
    "    for dx, dy in ((1, 0), (-1, 0), (0, 1), (0, -1)):\n",
    "        for image, label in zip(X_train, y_train):\n",
    "            X_train_augmented.append(shift_image(image, dx, dy))\n",
    "            y_train_augmented.append(label)\n",
    "    \n",
    "    X_train_augmented = np.array(X_train_augmented)\n",
    "    y_train_augmented = np.array(y_train_augmented)\n",
    "    \n",
    "    shuffle_idx = np.random.permutation(len(X_train_augmented))\n",
    "    X_train_augmented = X_train_augmented[shuffle_idx]\n",
    "    y_train_augmented = y_train_augmented[shuffle_idx]\n",
    "    \n",
    "    return X_train_augmented, y_train_augmented\n",
    "\n",
    "def plot_mnist(X, cmap='binary'):\n",
    "    \"\"\"\n",
    "    Função para plotar graficamente dígitos aleatórios do dataset MNIST\n",
    "    \"\"\"\n",
    "    some_digit = X[randint(0, X.shape[0])]\n",
    "    some_digit_reshaped = some_digit.reshape(28, 28)\n",
    "    plt.imshow(some_digit_reshaped, cmap=cmap, interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_data_augmented(X):\n",
    "    \"\"\"\n",
    "    Função responsável por plotar graficamente imagens deslocadas do dataset\n",
    "    \"\"\"\n",
    "    image = X[randint(0, X.shape[0])]\n",
    "    shifted_image_down = shift_image(image, 0, 5)\n",
    "    shifted_image_left = shift_image(image, -5, 0)\n",
    "    shifted_image_up = shift_image(image, 0, -5)\n",
    "    shifted_image_right = shift_image(image, 5, 0)\n",
    "    \n",
    "    # Criando figure e plotando gráficos\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.subplot(151)\n",
    "    plt.title('Original', fontsize=14)\n",
    "    plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.subplot(152)\n",
    "    plt.title('Shifted down', fontsize=14)\n",
    "    plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.subplot(153)\n",
    "    plt.title('Shifted left', fontsize=14)\n",
    "    plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.subplot(154)\n",
    "    plt.title('Shifted up', fontsize=14)\n",
    "    plt.imshow(shifted_image_up.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    plt.subplot(155)\n",
    "    plt.title('Shifted right', fontsize=14)\n",
    "    plt.imshow(shifted_image_right.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com a definição das funções e importação das bibliotecas necessárias, os códigos a seguir terão como objetivo mostrar um pouco mais sobre o dataset MNIST, como o download e plotagens dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:37:58.514474Z",
     "start_time": "2019-01-06T19:37:58.409685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Realizando o download e a preparação dos dados\n",
    "X_train, y_train, X_test, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:37:59.318943Z",
     "start_time": "2019-01-06T19:37:59.186577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAABspJREFUeJzt3TtrVGsDhuHJx1YJiOKpisEiHkBEEJQgBBT9AWolpguiBCwVGxsLsZFIEBV/gIVWgoUgCAYDHgpFiUQQUyjYpNJClDSz612sd803KxOTPNfVPq5ZMeZmFa8z6Wu32y0gz//+9hcA/B3ih1Dih1Dih1Dih1Dih1Dih1Dih1Dih1D/LPH9/HdC6L2+Tv6QJz+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EEj+EWupf0c0KMzo6WtwfPHhQ3MfGxiq3oaGh4rUXL14s7uvWrSvulHnyQyjxQyjxQyjxQyjxQyjxQyjxQ6i+dru9lPdb0ptR78uXL8V99+7dxb2vr28xv5z/OHToUHF//fp1z+69wnX0j+LJD6HED6HED6HED6HED6HED6HED6Gc869yCwsLxX14eLi4f/jwobj38py/ztmzZ4v77du3K7e1a9cu9peznDjnB6qJH0KJH0KJH0KJH0KJH0I56lvlpqamivvx48eLe93PR91R38DAQOX2/fv34rV16r6258+fV25HjhxpdO9lzlEfUE38EEr8EEr8EEr8EEr8EEr8EMqv6F4Ffv/+Xbldv3690Wtv2rSpuD98+LC479u3r3K7efNm8dqJiYniXmdmZqZyW+Xn/B3x5IdQ4odQ4odQ4odQ4odQ4odQ4odQ3s+/Avz8+bO4nzhxonJ78eJFo3uPj48X97t373b92nWfNXDs2LHiXvezu2vXrsrt3bt3xWvXr19f3Jc57+cHqokfQokfQokfQokfQokfQokfQnk//wpw4cKF4j49PV251X2u/s6dO4v7lStXinsTW7duLe4bN24s7nX//2Fubq5yK30GQqu14s/5O+LJD6HED6HED6HED6HED6HED6HED6Gc8y8D8/Pzxf3ly5ddv/aOHTuK+7Nnz4r7wMBA1/euU/pM/1ar1dq+fXtxrzvnp8yTH0KJH0KJH0KJH0KJH0KJH0I56lsGbty4Udy/fv3a9WuPjIwU98HBwa5fm5XNkx9CiR9CiR9CiR9CiR9CiR9CiR9COedfAjMzM8V9YmKiuNd9/Hbpo72vXbtWvJZcnvwQSvwQSvwQSvwQSvwQSvwQSvwQyjn/Ivj8+XNxP3r0aHFvt9uN7n/q1KnKbcOGDY1e+2+q+77U7QcOHKjcEn4Fdx1PfgglfgglfgglfgglfgglfgglfgjlnH8RTE9PF/cfP34U97r36587d6641302/3L1/v374v7t27fiXvd9u3TpUuXW399fvDaBJz+EEj+EEj+EEj+EEj+EEj+EEj+Ecs7foV+/flVuk5OTPb336OhocV+zZk1P79/E1NRU5Xb58uXitaXveavVau3Zs6e4Hz58uLin8+SHUOKHUOKHUOKHUOKHUOKHUI76OvTo0aPKbXZ2ttFrDw4OFve9e/c2ev1emp+fL+6l47y3b982uvenT58aXZ/Okx9CiR9CiR9CiR9CiR9CiR9CiR9COefv0NzcXM9eu+6jubdt29azezc1Pj5e3Juc5Z85c6bra6nnyQ+hxA+hxA+hxA+hxA+hxA+hxA+hnPN3qN1ud7V1YmhoqNH1vbR///7i/vHjx65fe3h4uLjfunWr69emnic/hBI/hBI/hBI/hBI/hBI/hBI/hHLO36G+vr6utk708n3rr169Ku5Pnz4t7nXn+HV/94MHD1Zujx8/Ll67efPm4k4znvwQSvwQSvwQSvwQSvwQSvwQylHfMnD16tXiXnec9ufPn8ptcnKyeO3CwkJxr1M6ymu1Wq0nT55Ublu2bGl0b5rx5IdQ4odQ4odQ4odQ4odQ4odQ4odQfU0/dvr/tKQ3W0yzs7OV2/nz54vX1r2ttu7foOlbhps4efJkcb93715xX86/XnwV6+gHxpMfQokfQokfQokfQokfQokfQokfQjnnXwRv3rwp7vfv3y/ud+7cKe515/z9/f2V29jYWPHa06dPF/eRkZHizrLknB+oJn4IJX4IJX4IJX4IJX4IJX4I5ZwfVh/n/EA18UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UMo8UOof5b4fh396mCg9zz5IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IZT4IdS/RNoDq7+DWygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2083bc837f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando dados\n",
    "plot_mnist(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:38:00.631276Z",
     "start_time": "2019-01-06T19:38:00.621306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_train: (60000, 784)\n",
      "Dimensões de y_train: (60000,)\n",
      "\n",
      "Dimensões de X_test: (10000, 784)\n",
      "Dimensões de y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando dimensões\n",
    "print(f'Dimensões de X_train: {X_train.shape}')\n",
    "print(f'Dimensões de y_train: {y_train.shape}')\n",
    "print()\n",
    "print(f'Dimensões de X_test: {X_test.shape}')\n",
    "print(f'Dimensões de y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trata-se de um dataset com imagens de dimensões 28x28 (totalizando 784 features). Os dados de treino possuem 60000 registros, enquanto os dados de teste são compostos por 10000 registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:38:02.385569Z",
     "start_time": "2019-01-06T19:38:02.270816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2083bc40d30>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotagem diferenciada\n",
    "plot_mnist(X_train, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro algoritmo utilizado será o ```DecisionTrees```: [Doc](https://scikit-learn.org/stable/modules/tree.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:38:04.445244Z",
     "start_time": "2019-01-06T19:38:04.433278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Como é a primeira análise, temos que criar um dataset vazio\n",
    "dataset_accs, dict_accs_tree = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:38:06.082485Z",
     "start_time": "2019-01-06T19:38:06.065534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acc_train, acc_train_cv, acc_train_scaled, acc_test, acc_test_scaled, acc_test_grid, acc_test_shifted]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset criado\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:38:06.929471Z",
     "start_time": "2019-01-06T19:38:06.923455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dicionário criado para armazenar acurácias\n",
    "dict_accs_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:38:42.884881Z",
     "start_time": "2019-01-06T19:38:08.254471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do Decision Trees com dados de treino: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Criando classificador\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Treinando modelo (sem transformações)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Avaliando acurácia\n",
    "train_pred = dtree.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(f'Acurácia do Decision Trees com dados de treino: {train_acc:.4f}')\n",
    "\n",
    "# Salvando dados\n",
    "dict_accs_tree['acc_train'] = round(train_acc, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será um tremendo overfitting? Sempre é preciso desconfiar de uma grande acurácia nos dados de treino. Para verificar se realmente há a presença de overfitting, devemos aplicar o ```cross_validation```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:39:44.435319Z",
     "start_time": "2019-01-06T19:38:42.887944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.86182763 0.86124306 0.86192929]\n",
      "Média: 0.8617\n",
      "Desvio Padrão: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Aplicando validação cruzada\n",
    "tree_scores = cross_val_score(dtree, X_train, y_train,\n",
    "                             cv=3, scoring='accuracy')\n",
    "display_scores(tree_scores)\n",
    "\n",
    "# Salvando dados\n",
    "dict_accs_tree['acc_train_cv'] = round(tree_scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A diminuição da acurácia através da aplicação do ```cross validation``` mostra que realmente o modelo ```DecisionTrees``` é muito sensível ao overfitting.\n",
    "\n",
    "Na tentativa de melhorar essa performance, vamos aplicar um processo de ```padronização``` nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T19:43:35.351608Z",
     "start_time": "2019-01-06T19:41:56.261408Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.85972805 0.86089304 0.8606791 ]\n",
      "Média: 0.8604\n",
      "Desvio Padrão: 0.0005\n"
     ]
    }
   ],
   "source": [
    "# Padronizando dados\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "# Realizando um novo treinamento\n",
    "dtree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Verificando nova acurácia com cross validation\n",
    "tree_scores_scaled = cross_val_score(dtree, X_train_scaled, y_train,\n",
    "                                    cv=3, scoring='accuracy')\n",
    "\n",
    "# Comunicando resultados\n",
    "display_scores(tree_scores_scaled)\n",
    "\n",
    "# Salvando dados\n",
    "dict_accs_tree['acc_train_scaled'] = round(tree_scores_scaled.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não houve alterações significativas. Inclusive foi identificado um decréscimo mínimo na acurácia.\n",
    "\n",
    "Assim, é possível concluir que o modelo ```DecisionTrees``` não é sensível a padronização dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunando Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T20:34:37.188625Z",
     "start_time": "2019-01-06T19:43:43.858248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, score=0.8591781643671266, total=  21.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, score=0.8609430471523576, total=  19.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   40.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, score=0.8630794619192879, total=  21.2s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, score=0.860877824435113, total=  21.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, score=0.8580429021451073, total=  19.3s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=10, score=0.8612291843776566, total=  21.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20, score=0.8565286942611477, total=  20.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20, score=0.8541927096354818, total=  19.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=20, score=0.8566284942741411, total=  21.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, score=0.862127574485103, total=  17.2s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, score=0.8581929096454822, total=  17.4s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, score=0.8670300545081763, total=  18.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, score=0.8617776444711058, total=  18.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, score=0.8590929546477324, total=  16.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=10, score=0.8660299044856729, total=  18.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20, score=0.8607778444311138, total=  17.8s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20, score=0.8565928296414821, total=  17.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=20, score=0.8621293193979097, total=  18.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2, score=0.8582783443311338, total=  16.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2, score=0.855892794639732, total=  15.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=2, score=0.8633294994249138, total=  15.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10, score=0.8583283343331334, total=  16.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10, score=0.856392819640982, total=  16.4s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=10, score=0.8628794319147872, total=  17.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20, score=0.8583283343331334, total=  18.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20, score=0.855942797139857, total=  17.8s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=10, min_samples_split=20, score=0.862529379406911, total=  17.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, score=0.6662667466506699, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, score=0.6806340317015851, total=   5.8s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, score=0.6674501175176276, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, score=0.6662667466506699, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, score=0.6806340317015851, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=10, score=0.6674501175176276, total=   6.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20, score=0.6662667466506699, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20, score=0.6806340317015851, total=   6.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=20, score=0.6674501175176276, total=   6.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, score=0.6662667466506699, total=   6.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, score=0.6806340317015851, total=   6.5s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, score=0.6674501175176276, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, score=0.6662667466506699, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, score=0.6806340317015851, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=10, score=0.6674501175176276, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20, score=0.6662667466506699, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20, score=0.6805340267013351, total=   5.8s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=20, score=0.6674501175176276, total=   6.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2, score=0.6662667466506699, total=   6.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2, score=0.6806340317015851, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=2, score=0.6674501175176276, total=   6.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10, score=0.6662667466506699, total=   6.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10, score=0.6806340317015851, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=10, score=0.6674501175176276, total=   6.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20, score=0.6662667466506699, total=   6.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20, score=0.6805340267013351, total=   6.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=10, min_samples_split=20, score=0.6674501175176276, total=   6.1s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, score=0.8450809838032394, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, score=0.847942397119856, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, score=0.8523778566785017, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, score=0.8437312537492502, total=  11.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, score=0.8470923546177309, total=  10.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=10, score=0.8525278791818773, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20, score=0.8415316936612678, total=  10.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20, score=0.8453922696134807, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=20, score=0.8498274741211181, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, score=0.8437812437512497, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, score=0.847792389619481, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, score=0.8507776166424964, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, score=0.8437312537492502, total=  11.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, score=0.847842392119606, total=  10.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=10, score=0.8510776616492474, total=  10.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20, score=0.8419316136772645, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20, score=0.8465923296164808, total=  11.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=20, score=0.8492773916087413, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2, score=0.8402819436112777, total=  10.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2, score=0.8445922296114806, total=  10.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=2, score=0.8484772715907386, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10, score=0.8406818636272746, total=  10.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10, score=0.8446422321116056, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=10, score=0.8480772115817372, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20, score=0.840381923615277, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20, score=0.8446922346117306, total=  10.4s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=10, min_samples_split=20, score=0.848277241586238, total=  10.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, score=0.8638272345530894, total=  14.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, score=0.8631431571578579, total=  14.5s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, score=0.8673300995149272, total=  15.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10, score=0.861127774445111, total=  14.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10, score=0.8622431121556078, total=  14.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=10, score=0.8646797019552933, total=  14.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20, score=0.8575284943011398, total=  14.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20, score=0.8569928496424821, total=  14.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=20, score=0.8590288543281492, total=  14.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, score=0.863377324535093, total=  14.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, score=0.8596929846492325, total=  13.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, score=0.8665299794969246, total=  13.9s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10, score=0.8620275944811038, total=  14.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10, score=0.8605430271513576, total=  13.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=10, score=0.866079911986798, total=  14.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20, score=0.8598280343931214, total=  14.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20, score=0.8576928846442322, total=  14.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=20, score=0.8619792968945342, total=  14.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2, score=0.8582783443311338, total=  13.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2, score=0.856292814640732, total=  13.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=2, score=0.8636295444316647, total=  13.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10, score=0.8580283943211358, total=  13.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10, score=0.8569428471423571, total=  14.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=10, score=0.8636295444316647, total=  13.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20, score=0.8582783443311338, total=  13.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20, score=0.8569428471423571, total=  13.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=10, min_samples_split=20, score=0.8630794619192879, total=  13.5s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, score=0.8697260547890422, total=  18.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, score=0.8658432921646082, total=  19.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, score=0.8704305645846877, total=  20.2s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, score=0.8697260547890422, total=  19.2s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, score=0.8633431671583579, total=  14.5s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=10, score=0.8668800320048007, total=  18.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20, score=0.8660267946410718, total=  18.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20, score=0.8587429371468573, total=  18.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=20, score=0.8653297994699205, total=  18.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, score=0.870875824835033, total=  18.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, score=0.8671433571678584, total=  18.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, score=0.8697304595689354, total=  18.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, score=0.8691261747650469, total=  18.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, score=0.8669933496674834, total=  18.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=10, score=0.8699804970745612, total=  18.9s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20, score=0.8674765046990602, total=  18.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20, score=0.8619430971548577, total=  18.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=20, score=0.8667300095014252, total=  18.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2, score=0.8647770445910817, total=  17.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2, score=0.8611930596529827, total=  17.9s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=2, score=0.8641296194429164, total=  18.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10, score=0.8647770445910817, total=  17.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10, score=0.8603430171508576, total=  17.9s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=10, score=0.8646296944541682, total=  18.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20, score=0.8647270545890822, total=  17.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20, score=0.8613430671533576, total=  17.5s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=10, min_samples_split=20, score=0.8637795669350402, total=  18.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, score=0.6941611677664468, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, score=0.6942347117355868, total=   7.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, score=0.6902035305295794, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, score=0.6941611677664468, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, score=0.6942347117355868, total=   7.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=10, score=0.6902035305295794, total=   7.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20, score=0.6941611677664468, total=   7.8s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20, score=0.6942347117355868, total=   7.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=20, score=0.6902035305295794, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, score=0.6941611677664468, total=   7.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, score=0.6942347117355868, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, score=0.6902035305295794, total=   7.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, score=0.6941611677664468, total=   7.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, score=0.6942347117355868, total=   7.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=10, score=0.6902035305295794, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20, score=0.6941611677664468, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20, score=0.6942347117355868, total=   7.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=20, score=0.6902035305295794, total=   7.8s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2, score=0.6941611677664468, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2, score=0.6942347117355868, total=   7.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=2, score=0.6902035305295794, total=   7.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10, score=0.6941611677664468, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10, score=0.6942347117355868, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=10, score=0.6902035305295794, total=   7.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20, score=0.6941611677664468, total=   7.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20, score=0.6942347117355868, total=   7.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=10, min_samples_split=20, score=0.6902035305295794, total=   7.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, score=0.8628274345130974, total=  15.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, score=0.8580429021451073, total=  16.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, score=0.8599789968495274, total=  16.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, score=0.8612277544491101, total=  15.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, score=0.8575928796439822, total=  16.2s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=10, score=0.8596789518427764, total=  16.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20, score=0.8587282543491301, total=  16.6s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20, score=0.8544427221361068, total=  15.6s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=20, score=0.8563784567685153, total=  16.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, score=0.862127574485103, total=  15.6s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, score=0.8565928296414821, total=  15.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, score=0.8592288843326499, total=  15.8s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, score=0.8622275544891022, total=  15.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, score=0.8573928696434822, total=  15.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=10, score=0.8594289143371505, total=  16.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20, score=0.8594781043791242, total=  15.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20, score=0.8545427271363568, total=  15.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=20, score=0.8571285692853928, total=  15.8s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2, score=0.8581783643271346, total=  15.2s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2, score=0.8545427271363568, total=  15.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=2, score=0.8566284942741411, total=  15.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10, score=0.858378324335133, total=  15.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10, score=0.8541927096354818, total=  15.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=10, score=0.8561784267640146, total=  15.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20, score=0.8582783443311338, total=  15.2s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20, score=0.8542427121356068, total=  15.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=10, min_samples_split=20, score=0.8568785317797669, total=  15.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, score=0.8694261147770446, total=  19.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, score=0.8657432871643582, total=  19.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, score=0.8715307296094414, total=  19.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10, score=0.869376124775045, total=  20.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10, score=0.8655432771638581, total=  19.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=10, score=0.8701805270790619, total=  19.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20, score=0.8656768646270746, total=  19.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20, score=0.8610930546527327, total=  18.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=20, score=0.8656298444766715, total=  19.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, score=0.8705258948210358, total=  18.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, score=0.8674433721686085, total=  19.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, score=0.869030354553183, total=  19.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10, score=0.8714757048590281, total=  18.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10, score=0.8680934046702335, total=  18.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=10, score=0.8689303395509327, total=  19.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20, score=0.8669766046790642, total=  19.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20, score=0.8621931096554828, total=  18.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=20, score=0.8670800620093014, total=  19.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2, score=0.8638272345530894, total=  18.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2, score=0.8611930596529827, total=  18.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=2, score=0.8647797169575436, total=  19.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10, score=0.8642271545690862, total=  18.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10, score=0.8620931046552328, total=  18.5s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=10, score=0.8643796569485422, total=  18.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20, score=0.8645270945810838, total=  17.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20, score=0.8612930646532326, total=  18.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=10, min_samples_split=20, score=0.8642296344451668, total=  18.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 216 out of 216 | elapsed: 50.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'criterion': ['gini', 'entropy'], 'min_samples_split': [2, 10, 20], 'max_depth': [None, 5, 10, 15], 'min_samples_leaf': [1, 5, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definindo parâmetros para Decision Trees\n",
    "param_grid_tree = [\n",
    "    {\n",
    "     'criterion': ['gini', 'entropy'],\n",
    "     'min_samples_split': [2, 10, 20],\n",
    "     'max_depth': [None, 5, 10, 15],\n",
    "     'min_samples_leaf': [1, 5, 10]\n",
    "     #'max_leaf_nodes': [None, 5, 10, 20]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Criando classificador\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Treinando e procurando a melhor combinação\n",
    "grid_search_tree = GridSearchCV(dtree, param_grid_tree, cv=3, \n",
    "                           scoring='accuracy', verbose=3)\n",
    "\n",
    "grid_search_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T21:50:29.488507Z",
     "start_time": "2019-01-06T21:50:29.481527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 15,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 10}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os melhores parâmetros\n",
    "grid_search_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T21:50:46.100368Z",
     "start_time": "2019-01-06T21:50:46.094295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o melhor score\n",
    "grid_search_tree.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T21:50:55.122800Z",
     "start_time": "2019-01-06T21:50:55.113824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acc_train, acc_train_cv, acc_train_scaled, acc_test, acc_test_scaled, acc_test_grid, acc_test_shifted]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T21:54:30.407087Z",
     "start_time": "2019-01-06T21:54:30.401102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_train': 1.0, 'acc_train_cv': 0.8617, 'acc_train_scaled': 0.8604}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_accs_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T21:53:29.164909Z",
     "start_time": "2019-01-06T21:53:29.076954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8878"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = grid_search_tree.best_estimator_\n",
    "p = m.predict(X_test)\n",
    "accuracy_scorecore(y_test, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:39:27.916868Z",
     "start_time": "2019-01-06T22:38:53.676825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados de teste: 0.8800\n"
     ]
    }
   ],
   "source": [
    "# Calculando acurácia nos dados de teste\n",
    "dtree.fit(X_train, y_train)\n",
    "pred_test = dtree.predict(X_test)\n",
    "\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "print(f'Acurácia nos dados de teste: {acc_test:.4f}')\n",
    "\n",
    "# Salvando valores\n",
    "dict_accs_tree['acc_test'] = round(acc_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizando uma comparação com a primeira acurácia obtida nos dados de treino, percebe-se que saímos de incríveis (e enganosos) 100% de acurácia para 87,67%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:01:47.303894Z",
     "start_time": "2019-01-06T22:01:10.234513Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados de teste após padronização: 0.6226\n"
     ]
    }
   ],
   "source": [
    "# Tentativas de melhora: padronização nos dados\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "dtree.fit(X_train_scaled, y_train)\n",
    "pred_test_scaled = dtree.predict(X_test_scaled)\n",
    "\n",
    "acc_test_scaled = accuracy_score(y_test, pred_test_scaled)\n",
    "print(f'Acurácia nos dados de teste após padronização: {acc_test_scaled:.4f}')\n",
    "\n",
    "# Salvando resultado\n",
    "dict_accs_tree['acc_test_scaled'] = round(acc_test_scaled, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um resultado bem aquém do esperado, provando mais uma vez que o algoritmo ```Decision Trees``` não é sensível à padronização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:24:53.738695Z",
     "start_time": "2019-01-06T22:24:26.006363Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados de teste com os melhores parâmetros: 0.8890\n"
     ]
    }
   ],
   "source": [
    "# Verificação nos dados de teste com os melhores parâmetros (GridSearchCV)\n",
    "dtree_final = grid_search_tree.best_estimator_\n",
    "\n",
    "# Treinando modelo e verificando\n",
    "dtree_final.fit(X_train, y_train)\n",
    "pred_test = dtree_final.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "# Comunicando resultado\n",
    "print(f'Acurácia nos dados de teste com os melhores parâmetros: {acc_test:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_tree['acc_test_grid'] = round(acc_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Houve um ganho de mais de 1% de acurácia através da aplicação do ```GridSearchCV```, o que pode ser considerado excelente! Porém ainda há espaço para mais aprimoramento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este procedimento é um tanto quanto comum em problemas de classificação utilizando imagens. Com ele, é possível aumentar o conjunto de dados de treinamento através do deslocamento de pixels em alguma direção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:10:43.805756Z",
     "start_time": "2019-01-06T22:09:58.463040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retornando novo dataset com imagens deslocadas\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:12:35.592832Z",
     "start_time": "2019-01-06T22:12:35.584853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_train: (60000, 784)\n",
      "Dimensões de y_train: (60000,)\n",
      "\n",
      "Dimensões de X_train_augmented: (300000, 784)\n",
      "Dimensões de y_train_augmented: (300000,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando novas dimensões obtidas\n",
    "print(f'Dimensões de X_train: {X_train.shape}')\n",
    "print(f'Dimensões de y_train: {y_train.shape}')\n",
    "print()\n",
    "print(f'Dimensões de X_train_augmented: {X_train_augmented.shape}')\n",
    "print(f'Dimensões de y_train_augmented: {y_train_augmented.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebe-se que houve um aumento na quantidade de linhas dos conjuntos de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:13:46.048064Z",
     "start_time": "2019-01-06T22:13:45.554602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2080065ac18>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando gráficos\n",
    "plot_data_augmented(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:35:56.204629Z",
     "start_time": "2019-01-06T22:33:05.372260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia após transformação dos dados: 0.9211\n"
     ]
    }
   ],
   "source": [
    "# Realizando o treinamento com novos dados adquiridos\n",
    "dtree_final = grid_search_tree.best_estimator_\n",
    "\n",
    "dtree_final.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Predizendo valores\n",
    "y_pred = dtree_final.predict(X_test)\n",
    "y_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Comunicando resultados\n",
    "print(f'Acurácia após transformação dos dados: {y_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:38:30.444154Z",
     "start_time": "2019-01-06T22:38:30.440164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando resultados\n",
    "dict_accs_tree['acc_test_shifted'] = round(y_acc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:39:27.925807Z",
     "start_time": "2019-01-06T22:39:27.918824Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_test': 0.88,\n",
       " 'acc_test_grid': 0.889,\n",
       " 'acc_test_scaled': 0.6226,\n",
       " 'acc_test_shifted': 0.9211,\n",
       " 'acc_train': 1.0,\n",
       " 'acc_train_cv': 0.8617,\n",
       " 'acc_train_scaled': 0.8604}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando dados salvos até o momento\n",
    "dict_accs_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:36:40.017894Z",
     "start_time": "2019-01-06T22:36:39.999901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [acc_train, acc_train_cv, acc_train_scaled, acc_test, acc_test_scaled, acc_test_grid, acc_test_shifted]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:39:59.651912Z",
     "start_time": "2019-01-06T22:39:59.071009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0        1.0        0.8617            0.8604      0.88           0.6226   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0          0.889            0.9211  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando dados em um objeto DataFrame\n",
    "dataset_accs = dataset_accs.append(dict_accs_tree, ignore_index=True)\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:41:18.899555Z",
     "start_time": "2019-01-06T22:41:18.887588Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando dados\n",
    "save_dataset(dataset_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em resumo, alguns pontos podem ser levantados sobre o algoritimo ```Decision Tree``` na classificação de digitos manuscritos contidos no dataset MNIST:\n",
    "    - As Árvores de Decisão são muito suscetíveis a Overfitting;\n",
    "    - Padronização nos dados não melhoram a performance do algoritmo;\n",
    "    - A acurácia final (após o deslocamento das imagens) é relativamente baixa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O segundo algoritmo utilizado será o ```SGDClassifier```. [Doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:42:00.304955Z",
     "start_time": "2019-01-06T22:42:00.289041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0        1.0        0.8617            0.8604      0.88           0.6226   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0          0.889            0.9211  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo dataset\n",
    "dataset_accs = load_dataset()\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:42:20.583492Z",
     "start_time": "2019-01-06T22:42:20.578506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dicionário criado para armazenar acurácias\n",
    "dict_accs_sgd = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:44:36.757821Z",
     "start_time": "2019-01-06T22:44:29.161021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida com SGD Classifier nos dados de treino: 0.8825\n"
     ]
    }
   ],
   "source": [
    "# Criando classificadoor\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "# Treinando modelo\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predizendo\n",
    "train_pred = sgd_clf.predict(X_train)\n",
    "\n",
    "# Acurácia\n",
    "acc_train = accuracy_score(y_train, train_pred)\n",
    "\n",
    "# Comunicando resultados\n",
    "print(f'Acurácia obtida com SGD Classifier nos dados de treino: {acc_train:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_sgd['acc_train'] = round(acc_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando ```cross validation``` para verificar a presença de overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:46:24.791483Z",
     "start_time": "2019-01-06T22:46:11.787421Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.87342531 0.87849392 0.85142771]\n",
      "Média: 0.8678\n",
      "Desvio Padrão: 0.0117\n"
     ]
    }
   ],
   "source": [
    "# Aplicando validação cruzada\n",
    "sgd_scores = cross_val_score(sgd_clf, X_train, y_train,\n",
    "                            cv=3, scoring='accuracy')\n",
    "\n",
    "display_scores(sgd_scores)\n",
    "\n",
    "# Salvando dados\n",
    "dict_accs_sgd['acc_train_cv'] = round(sgd_scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A queda na performance não foi significativa, indicando assim que o algoritmo de Classificação Stocástica não é tão suscetível ao overfitting. Ainda há espaços para melhorias através da padronização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T22:51:00.654867Z",
     "start_time": "2019-01-06T22:50:38.903640Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.90696861 0.91109555 0.91233685]\n",
      "Média: 0.9101\n",
      "Desvio Padrão: 0.0023\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a padronização dos dados\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "# Realizando novo treinamento e avaliação\n",
    "sgd_clf.fit(X_train_scaled, y_train)\n",
    "scaled_scores = cross_val_score(sgd_clf, X_train_scaled, y_train,\n",
    "                               cv=3, scoring='accuracy')\n",
    "display_scores(scaled_scores)\n",
    "\n",
    "# Salvando dados\n",
    "dict_accs_sgd['acc_train_scaled'] = round(scaled_scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Houve uma significativa melhora na performance do algoritmo, indicando que a padronização dos dados pode ser algo bem interessante para modelos treinados com ```SGD Classifier```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunando Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-06T23:12:10.909395Z",
     "start_time": "2019-01-06T22:53:03.937127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.9016696660667867, total=  12.1s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.2s remaining:    0.0s\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.9058452922646132, total=  12.2s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   24.7s remaining:    0.0s\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.9046857028554283, total=  14.1s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   39.1s remaining:    0.0s\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.907118576284743, total=   4.2s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.9108455422771139, total=   4.4s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.9110366554983248, total=   3.7s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.9005698860227954, total=  10.1s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.9053452672633632, total=   8.2s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.9017852677901685, total=   7.6s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.9063687262547491, total=   2.7s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.9107955397769888, total=   2.6s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.9110366554983248, total=   2.5s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=log, penalty=l1, score=0.9015696860627874, total=   8.8s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=log, penalty=l1, score=0.9058952947647383, total=   8.8s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=log, penalty=l1, score=0.9036355453317998, total=   8.8s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=log, penalty=l2, score=0.9057188562287543, total=   4.4s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=log, penalty=l2, score=0.9088454422721136, total=   4.7s\n",
      "[CV] alpha=0.0001, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0001, learning_rate=optimal, loss=log, penalty=l2, score=0.9113867080062009, total=   4.2s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8889722055588882, total=   6.6s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8912945647282364, total=   6.8s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8887833174976246, total=   6.6s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8999700059988003, total=   2.6s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.904295214760738, total=   2.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.902535380307046, total=   2.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8845730853829235, total=   6.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.888044402220111, total=   6.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8854328149222384, total=   7.1s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.9004199160167966, total=   2.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.903895194759738, total=   2.8s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.901335200280042, total=   2.6s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l1, score=0.889622075584883, total=  13.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l1, score=0.8920946047302365, total=  13.6s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l1, score=0.889183377506626, total=  13.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l2, score=0.8991701659668067, total=   4.7s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l2, score=0.9049452472623631, total=   5.2s\n",
      "[CV] alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0012000000000000001, learning_rate=optimal, loss=log, penalty=l2, score=0.9014852227834175, total=   4.8s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8818236352729454, total=   6.7s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8874943747187359, total=   6.7s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8844326648997349, total=   6.6s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l2, score=0.896870625874825, total=   2.7s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l2, score=0.9026951347567378, total=   2.6s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=hinge, penalty=l2, score=0.9005350802620393, total=   2.6s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8760247950409918, total=   6.9s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8872443622181109, total=   6.5s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8803320498074712, total=   6.8s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.898870225954809, total=   2.7s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8995949797489875, total=   2.9s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8991348702305346, total=   2.7s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=log, penalty=l1, score=0.8826734653069386, total=  13.4s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=log, penalty=l1, score=0.8904445222261113, total=  13.7s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=log, penalty=l1, score=0.8827824173626044, total=  13.4s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=log, penalty=l2, score=0.8985702859428114, total=   4.5s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=log, penalty=l2, score=0.9014450722536127, total=   4.6s\n",
      "[CV] alpha=0.0023, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0023, learning_rate=optimal, loss=log, penalty=l2, score=0.8992348852327849, total=   4.6s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8750749850029994, total=   6.2s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8819440972048602, total=   6.2s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l1, score=0.879681952292844, total=   6.3s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8956708658268346, total=   2.6s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8982949147457373, total=   2.7s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8974346151922789, total=   2.6s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8699260147970406, total=   6.4s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8831441572078604, total=   6.2s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8738310746611991, total=   7.0s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8959208158368326, total=   2.6s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.9001450072503625, total=   2.6s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.898384757713657, total=   2.7s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=log, penalty=l1, score=0.8784743051389722, total=  13.7s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=log, penalty=l1, score=0.8821441072053603, total=  12.7s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=log, penalty=l1, score=0.8774316147422113, total=  13.6s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=log, penalty=l2, score=0.8955208958208358, total=   4.5s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=log, penalty=l2, score=0.9023951197559879, total=   4.5s\n",
      "[CV] alpha=0.0034, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0034, learning_rate=optimal, loss=log, penalty=l2, score=0.8999349902485373, total=   4.6s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8671265746850629, total=   6.5s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8814940747037352, total=   6.2s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8737310596589488, total=   6.2s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l2, score=0.895870825834833, total=   2.6s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l2, score=0.9006950347517376, total=   2.6s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8955843376506476, total=   2.7s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8674765046990602, total=   6.1s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8789939496974849, total=   6.2s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8738810821623243, total=   6.2s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8945210957808438, total=   2.7s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8997449872493625, total=   2.6s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8966344951742762, total=   2.6s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l1, score=0.8745250949810038, total=  13.3s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l1, score=0.8743937196859843, total=  13.0s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l1, score=0.8698804820723108, total=  12.7s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l2, score=0.8937712457508499, total=   4.5s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l2, score=0.8998449922496125, total=   4.6s\n",
      "[CV] alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0045000000000000005, learning_rate=optimal, loss=log, penalty=l2, score=0.8934340151022654, total=   4.5s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8586782643471306, total=   6.2s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8745437271863593, total=   6.2s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8723808571285693, total=   6.2s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8948210357928414, total=   2.7s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8983449172458623, total=   2.6s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=hinge, penalty=l2, score=0.895134270140521, total=   2.6s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8622775444911018, total=   6.4s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8705435271763589, total=   6.3s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8642796419462919, total=   6.3s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8947710457908419, total=   2.6s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8984949247462373, total=   2.6s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.893934090113517, total=   2.8s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l1, score=0.865626874625075, total=  12.2s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l1, score=0.8747437371868594, total=  13.4s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l1, score=0.8695804370655599, total=  12.4s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l2, score=0.8941711657668466, total=   4.6s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l2, score=0.8996449822491125, total=   4.5s\n",
      "[CV] alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.005600000000000001, learning_rate=optimal, loss=log, penalty=l2, score=0.8942341351202681, total=   4.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8586782643471306, total=   5.9s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8697434871743587, total=   6.0s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8593789068360254, total=   6.0s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8930713857228554, total=   2.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8983449172458623, total=   2.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8975346301945292, total=   2.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8614277144571085, total=   6.0s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8642932146607331, total=   6.0s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8612791918787818, total=   5.9s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8935212957408518, total=   2.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8979948997449873, total=   2.7s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8959343901585238, total=   2.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=log, penalty=l1, score=0.857878424315137, total=  12.1s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=log, penalty=l1, score=0.8664933246662333, total=  12.0s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=log, penalty=l1, score=0.8627294094114117, total=  13.0s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=log, penalty=l2, score=0.8914717056588682, total=   4.6s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=log, penalty=l2, score=0.8952447622381119, total=   4.5s\n",
      "[CV] alpha=0.0067, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0067, learning_rate=optimal, loss=log, penalty=l2, score=0.8946341951292693, total=   4.5s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l1, score=0.858878224355129, total=   5.9s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8598429921496075, total=   5.8s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8499274891233685, total=   6.0s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8930713857228554, total=   2.6s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8993949697484874, total=   2.6s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8947842176326449, total=   2.6s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8482803439312138, total=   5.8s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8662933146657333, total=   6.9s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8466269940491074, total=   7.1s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8924715056988602, total=   3.0s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8973948697434871, total=   3.3s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8951842776416462, total=   3.6s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l1, score=0.8539292141571686, total=  14.8s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l1, score=0.8621931096554828, total=  12.6s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l1, score=0.8598789818472771, total=  12.5s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l2, score=0.8922215556888622, total=   5.0s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l2, score=0.8989949497474874, total=   4.8s\n",
      "[CV] alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0078000000000000005, learning_rate=optimal, loss=log, penalty=l2, score=0.8936840526078912, total=   7.3s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8473305338932213, total=   7.1s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8544427221361068, total=   6.7s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l1 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8590288543281492, total=   7.5s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8939212157568486, total=   2.8s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8975948797439872, total=   3.0s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l2 .....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8943341501225184, total=   2.8s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8552289542091581, total=   6.4s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8454922746137307, total=   6.7s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8529279391908786, total=   7.1s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8919716056788642, total=   2.8s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8970948547427371, total=   3.0s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8934340151022654, total=   2.8s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=log, penalty=l1, score=0.8420315936812638, total=  12.3s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=log, penalty=l1, score=0.8611430571528577, total=  12.6s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=log, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=log, penalty=l1, score=0.8482272340851128, total=  12.6s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=log, penalty=l2, score=0.890621875624875, total=   4.8s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=log, penalty=l2, score=0.896294814740737, total=   4.9s\n",
      "[CV] alpha=0.0089, learning_rate=optimal, loss=log, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.0089, learning_rate=optimal, loss=log, penalty=l2, score=0.8937840676101415, total=   4.7s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8380323935212958, total=   6.3s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8521926096304815, total=   6.1s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l1 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l1, score=0.8454768215232285, total=   6.5s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8941711657668466, total=   2.9s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8955447772388619, total=   2.9s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l2 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=hinge, penalty=l2, score=0.8958343751562734, total=   3.2s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8447310537892422, total=   6.2s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8523926196309816, total=   6.5s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l1 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l1, score=0.8435265289793469, total=   6.9s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l2 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8923215356928614, total=   2.9s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l2 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.895744787239362, total=   3.0s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l2 ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=perceptron, penalty=l2, score=0.8937340601090163, total=   3.0s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=log, penalty=l1 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=log, penalty=l1, score=0.8489802039592081, total=  12.3s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=log, penalty=l1 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=log, penalty=l1, score=0.8515425771288564, total=  12.4s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=log, penalty=l1 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=log, penalty=l1, score=0.8466770015502325, total=  12.4s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=log, penalty=l2 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=log, penalty=l2, score=0.8916716656668666, total=   5.0s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=log, penalty=l2 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=log, penalty=l2, score=0.8960948047402371, total=   4.9s\n",
      "[CV] alpha=0.01, learning_rate=optimal, loss=log, penalty=l2 .........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  alpha=0.01, learning_rate=optimal, loss=log, penalty=l2, score=0.8927339100865129, total=   5.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed: 19.0min finished\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'loss': ['hinge', 'perceptron', 'log'], 'penalty': ['l1', 'l2'], 'alpha': array([0.0001, 0.0012, 0.0023, 0.0034, 0.0045, 0.0056, 0.0067, 0.0078,\n",
       "       0.0089, 0.01  ]), 'learning_rate': ['optimal']}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=4)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo parâmetros para Decision Trees\n",
    "param_grid_sgd = [\n",
    "    {\n",
    "        'loss': ['hinge', 'perceptron', 'log'],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'alpha': np.linspace(0.0001, 0.01, 10),\n",
    "        'learning_rate': ['optimal']\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "# Criando classificador\n",
    "sgd_clf = SGDClassifier()\n",
    "\n",
    "# Treinando e procurando a melhor combinação\n",
    "grid_search = GridSearchCV(sgd_clf, param_grid_sgd, cv=3, \n",
    "                           scoring='accuracy', verbose=4)\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T00:05:06.460453Z",
     "start_time": "2019-01-07T00:05:06.454471Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'learning_rate': 'optimal', 'loss': 'hinge', 'penalty': 'l2'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhores hiperparâmetros\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T00:05:24.891966Z",
     "start_time": "2019-01-07T00:05:24.885987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096666666666666"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhor score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:21:04.286410Z",
     "start_time": "2019-01-07T01:21:04.280812Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_train': 0.8825, 'acc_train_cv': 0.8678, 'acc_train_scaled': 0.9101}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando scores até o momento\n",
    "dict_accs_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia (nos dados de treino) obtida através da aplicação do ```GridSearchCV``` não sofreu alterações com relação ao já obtido através da padronização dos dados. Provavalmente, maiores efeitos poderão ser visualizados com a avaliação nos dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:23:57.103109Z",
     "start_time": "2019-01-07T01:23:50.252452Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia obtida em SGD Classifier com os dados de teste: 0.8841\n"
     ]
    }
   ],
   "source": [
    "# Acurácia sem tratamento\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "test_pred = sgd_clf.predict(X_train)\n",
    "acc_test = accuracy_score(y_train, test_pred)\n",
    "\n",
    "# Comunicando resultados\n",
    "print(f'Acurácia obtida em SGD Classifier com os dados de teste: {acc_test:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_sgd['acc_test'] = round(acc_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valor relativamente próximo ao obtido com os dados de treino. Sem perdas significativas. Isto abre uma visão otimista sobre as melhorias possíveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:26:43.310186Z",
     "start_time": "2019-01-07T01:26:34.800079Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados de teste após padronização: 0.9139\n"
     ]
    }
   ],
   "source": [
    "# Treinando modelo com padronização\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "sgd_clf.fit(X_train_scaled, y_train)\n",
    "pred_scaled = sgd_clf.predict(X_test_scaled)\n",
    "\n",
    "acc_scaled = accuracy_score(y_test, pred_scaled)\n",
    "\n",
    "# Comunicando e salvando resultados\n",
    "print(f'Acurácia nos dados de teste após padronização: {acc_scaled:.4f}')\n",
    "dict_accs_sgd['acc_test_scaled'] = round(acc_scaled, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semelhante ao obtido com os dados de treino. Vamos avaliar agora a performance obtida com os hiperparâmetros retornados pela busca com ```GridSearchCV``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:29:12.136859Z",
     "start_time": "2019-01-07T01:29:06.227703Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia final (após GridSearchCV): 0.9139\n"
     ]
    }
   ],
   "source": [
    "# Avaliando resultado com os melhores parâmetros\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "acc_final = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia final (após GridSearchCV): {acc_final:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_sgd['acc_test_grid'] = round(acc_final, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exatamente idêntico ao resultado anterior. Vamos verificar a configuração de cada um dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:30:41.875830Z",
     "start_time": "2019-01-07T01:30:41.870546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo sgd_clf\n",
    "sgd_clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:30:51.552500Z",
     "start_time": "2019-01-07T01:30:51.546503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo grid_search\n",
    "model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A configuração obtida com o grid search foi exatamente idêntica a configuração padrão, o que explica os resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez, vamos aplicar a técnica de deslocamento de imagens para avantajar o conteúdo do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:34:03.053570Z",
     "start_time": "2019-01-07T01:33:18.106743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Alterando dataset\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:34:03.069525Z",
     "start_time": "2019-01-07T01:34:03.057557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 784)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando dimensões\n",
    "X_train_augmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:34:38.187948Z",
     "start_time": "2019-01-07T01:34:37.757070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20800d22860>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando digitos\n",
    "plot_data_augmented(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:39:24.389538Z",
     "start_time": "2019-01-07T01:38:51.208253Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia final após o deslocamento de pixels: 0.8532\n"
     ]
    }
   ],
   "source": [
    "# Treinando com o melhor modelo\n",
    "sgd_final = grid_search.best_estimator_\n",
    "sgd_final.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Realizando predições\n",
    "y_pred = sgd_final.predict(X_test)\n",
    "final_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Comunicando resultados\n",
    "print(f'Acurácia final após o deslocamento de pixels: {final_acc:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_sgd['acc_test_shifted'] = round(final_acc, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a análise dos resultados, alguns levantamentos podem ser feitos:\n",
    "    - SGD Classifier não é suscetível a overfitting (cross validation provou isso);\n",
    "    - A padronização dos dados auxiliou no aumento da performance do modelo;\n",
    "    - O hyperparameter tuning retornou uma combinação muito próximo do classificador padrão;\n",
    "    - Não houve melhoria através do processo data augmentation (pelo contrário, houve piora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T01:47:51.894536Z",
     "start_time": "2019-01-07T01:47:51.750267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0     1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "1     0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0         0.8890            0.9211  \n",
       "1         0.9139            0.8532  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando dados em dataset e salvando\n",
    "dataset_accs = dataset_accs.append(dict_accs_sgd, ignore_index=True)\n",
    "\n",
    "save_dataset(dataset_accs)\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Florestas Aleatórias \"é\" um algoritmo famoso e muito utilizado em diversos problemas. [Doc](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:12:28.128425Z",
     "start_time": "2019-01-07T18:12:27.117779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparando dados\n",
    "X_train, y_train, X_test, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:12:29.000378Z",
     "start_time": "2019-01-07T18:12:28.765843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d006d88860>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizando dígitos\n",
    "plot_mnist(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:12:30.405506Z",
     "start_time": "2019-01-07T18:12:30.116843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0     1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "1     0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0         0.8890            0.9211  \n",
       "1         0.9139            0.8532  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo dataset de resultados até o momento\n",
    "dataset_accs = load_dataset()\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que:\n",
    "    - 0: Decision Trees\n",
    "    - 1: SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:12:33.155061Z",
     "start_time": "2019-01-07T18:12:33.147354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criando dicionario vazio para armazenar performances\n",
    "dict_accs_forest = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:12:44.927246Z",
     "start_time": "2019-01-07T18:12:35.472650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Random Forest com os dados de treino: 0.9990\n"
     ]
    }
   ],
   "source": [
    "# Criando classificador\n",
    "forest = RandomForestClassifier()\n",
    "\n",
    "# Treinando modelo e avaliando performance\n",
    "forest.fit(X_train, y_train)\n",
    "train_pred = forest.predict(X_train)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "\n",
    "# Comunicando resultados\n",
    "print(f'Acurácia do modelo Random Forest com os dados de treino: {train_acc:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_train'] = round(train_acc, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o modelo ```Decision Trees``` é extremamente suscetível a overfitting, também o modelo ```Random Forest``` pode ser. A própria acurácia obtida nos dados de treinamento é um grande indício disso. Mais uma vez, para verificar tal teste, será usado o ```cross validation```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:12:57.602603Z",
     "start_time": "2019-01-07T18:12:44.929922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.94056189 0.94119706 0.94114117]\n",
      "Média: 0.9410\n",
      "Desvio Padrão: 0.0003\n"
     ]
    }
   ],
   "source": [
    "# Aplicando validação cruzada\n",
    "forest_scores = cross_val_score(forest, X_train, y_train,\n",
    "                               cv=3, scoring='accuracy')\n",
    "display_scores(forest_scores)\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_train_cv'] = round(forest_scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A queda da acurácia com a validação cruzada comprova que ```Random Forest``` tem tendências ao overfitting. Porém, com a queda menos acentuada que no modelo ```Decision Trees``` é possível prever que os resultados finais serão mais animadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T18:16:27.677949Z",
     "start_time": "2019-01-07T18:15:59.017658Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.94011198 0.94054703 0.94099115]\n",
      "Média: 0.9406\n",
      "Desvio Padrão: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# Aplicando padronização nos dados\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "\n",
    "forest_scores_scaled = cross_val_score(forest, X_train_scaled, y_train,\n",
    "                                      cv=3, scoring='accuracy')\n",
    "display_scores(forest_scores_scaled)\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_train_scaled'] = round(forest_scores_scaled.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como o modelo ```Decision Trees```, o algoritmo ```Random Forest``` não é sensível à padronização dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunando Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:29:57.962387Z",
     "start_time": "2019-01-07T18:24:07.672041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9112177564487103, total=   3.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.911745587279364, total=   2.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9091363704555684, total=   2.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9397620475904819, total=   5.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9386969348467423, total=   5.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9404910736610491, total=   5.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9558088382323535, total=  10.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9552477623881194, total=  10.8s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9541431214682202, total=  10.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9635072985402919, total=  25.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9635981799089954, total=  25.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9625443816572485, total=  24.4s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.914617076584683, total=   2.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.911895594779739, total=   2.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.916737510626594, total=   2.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9413617276544691, total=   5.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9427971398569929, total=   4.8s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9434915237285593, total=   5.2s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9565086982603479, total=   8.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9555477773888694, total=   9.3s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9553933089963494, total=  14.3s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9639072185562887, total=  27.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9630481524076204, total=  26.1s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9620443066459969, total=  25.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9196660667866426, total=   2.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9191959597979898, total=   2.4s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9191878781817273, total=   2.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9411617676464707, total=   4.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9407470373518676, total=   4.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9400410061509227, total=   4.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9524595080983803, total=   9.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9502475123756188, total=   9.2s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9510926638995849, total=   8.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9575084983003399, total=  21.4s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9558477923896195, total=  21.5s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9568435265289793, total=  22.8s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9185662867426515, total=   2.2s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.920146007300365, total=   2.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.917637645646847, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9412117576484703, total=   4.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9428971448572429, total=   4.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.940441066159924, total=   4.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9515096980603879, total=   8.9s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.951897594879744, total=   8.0s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9485422813422013, total=   9.2s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9568586282743451, total=  23.7s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9563978198909946, total=  22.6s\n",
      "[CV] criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9556933540031005, total=  20.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.7489502099580084, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.7623881194059703, total=   1.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.7525128769315397, total=   1.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.7997900419916016, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.7988899444972248, total=   2.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.8035205280792119, total=   1.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.8394821035792841, total=   4.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.8217910895544778, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.8360754113116967, total=   4.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8515296940611877, total=  10.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8579428971448573, total=   9.6s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8535780367055058, total=   9.7s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.7548990201959608, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.7730386519325966, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.7618642796419463, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.7978904219156169, total=   2.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.8116405820291015, total=   2.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.8154723208481273, total=   2.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.8393321335732853, total=   4.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.8366418320916046, total=   4.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.8250237535630345, total=   3.8s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.8564287142571486, total=   9.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.8536426821341067, total=   9.4s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.8451767765164775, total=  10.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.7655968806238752, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.7315865793289664, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.752562884432665, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.8163867226554689, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.8152407620381019, total=   1.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.8166725008751313, total=   2.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.8288842231553689, total=   4.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.8332416620831041, total=   4.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.8390758613792069, total=   3.8s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8533293341331734, total=  10.0s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8517925896294815, total=   9.7s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8541281192178827, total=   9.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.7626474705058989, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.7470373518675933, total=   1.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.747862179326899, total=   1.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.8010397920415917, total=   2.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.8088904445222261, total=   1.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.8049707456118418, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.8342831433713257, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.831291564578229, total=   4.1s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.845026754013102, total=   4.2s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.8518796240751849, total=   9.8s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.8485424271213561, total=   9.3s\n",
      "[CV] criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.8487273090963644, total=   9.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.8987702459508098, total=   2.1s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.8989449472473624, total=   2.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.898084712706906, total=   2.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9257648470305939, total=   3.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9234961748087405, total=   3.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9254388158223733, total=   3.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.936112777444511, total=   6.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9349967498374919, total=   6.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9338400760114017, total=   7.4s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9423115376924615, total=  17.4s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9420471023551178, total=  17.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9401910286542982, total=  16.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.8956208758248351, total=   2.2s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9028951447572379, total=   2.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.8958343751562734, total=   1.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9251149770045991, total=   3.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9185959297964899, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9241386207931189, total=   3.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9372125574885023, total=   7.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9360468023401171, total=   7.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.93334000100015, total=   7.1s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9428614277144571, total=  18.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9418470923546177, total=  16.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9428414262139321, total=  16.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.8997200559888022, total=   2.2s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9083954197709886, total=   1.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.8973346001900285, total=   1.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9219656068786243, total=   3.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9217460873043652, total=   3.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9188878331749762, total=   3.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9353129374125175, total=   7.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9335966798339917, total=   6.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9339900985147772, total=   6.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9412617476504699, total=  16.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9410470523526177, total=  24.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9411411711756763, total=  17.2s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9038192361527695, total=   1.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9007450372518626, total=   1.8s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9002350352552883, total=   1.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9245150969806039, total=   3.5s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9222961148057403, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9233885082762414, total=   3.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9353129374125175, total=   7.0s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9326966348317416, total=   6.9s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9331399709956494, total=   6.6s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9397620475904819, total=  16.7s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9388469423471174, total=  17.3s\n",
      "[CV] criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9400410061509227, total=  17.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9112677464507098, total=   2.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9111955597779889, total=   2.5s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9100365054758214, total=   2.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9395120975804839, total=   4.5s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9403970198509926, total=   4.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9379906986047907, total=   4.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9544591081783643, total=   8.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.951947597379869, total=   8.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9520928139220883, total=   9.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9613577284543091, total=  21.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9594479723986199, total=  22.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9597439615942391, total=  21.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9181663667266546, total=   2.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9168458422921146, total=   2.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9166875031254689, total=   2.5s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9413117376524696, total=   4.9s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9426971348567429, total=   5.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9386407961194179, total=   5.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9532093581283744, total=   8.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9541477073853692, total=   8.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9526929039355904, total=   8.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9616576684663067, total=  21.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9592479623981199, total=  22.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9593939090863629, total=  23.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9179164167166567, total=   2.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9194459722986149, total=   2.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9213882082312347, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9397120575884823, total=   4.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9389969498474924, total=   4.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9361404210631594, total=   4.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9490101979604079, total=   8.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9474473723686184, total=   8.8s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9491423713557033, total=   8.7s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9572085582883423, total=  23.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9545477273863693, total=  20.4s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.953493023953593, total=  20.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9171665666866626, total=   2.0s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9163458172908645, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.91408711306696, total=   2.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9400619876024795, total=   4.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9402970148507426, total=   4.2s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9371405710856628, total=   4.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9517596480703859, total=   9.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9512975648782439, total=   8.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.947842176326449, total=   8.1s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9558088382323535, total=  19.6s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9551977598879944, total=  21.3s\n",
      "[CV] criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=gini, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9545931889783468, total=  20.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9129674065186962, total=   3.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9163958197909895, total=   3.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.911686753012952, total=   3.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9449610077984403, total=   6.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9421471073553678, total=   6.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9401910286542982, total=   6.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9565586882623476, total=  12.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9544977248862443, total=  12.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9539430914637196, total=  12.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9639572085582884, total=  31.9s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9630481524076204, total=  31.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9615942391358704, total=  32.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9221155768846231, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9183959197959898, total=   3.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9159873981097164, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9447610477904419, total=   6.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9421971098554928, total=   6.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9442416362454368, total=   6.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9560587882423516, total=  13.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9568978448922446, total=  13.0s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9541431214682202, total=  12.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9630573885222955, total=  29.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9621481074053703, total=  30.2s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9606440966144921, total=  31.0s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9194661067786443, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9218960948047402, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9202880432064809, total=   3.2s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9443111377724455, total=   5.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9415970798539927, total=   6.0s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9414912236835525, total=   7.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9526094781043791, total=  12.0s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.951897594879744, total=  12.4s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9503425513827074, total=  12.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9571585682863427, total=  30.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9583479173958698, total=  28.8s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9563434515177277, total=  30.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9199660067986403, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9235461773088655, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.919387908186228, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9430613877224555, total=   6.2s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9414470723536177, total=   6.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9418912836925539, total=   6.6s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9515596880623876, total=  12.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9508975448772439, total=  13.3s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9512426864029604, total=  13.0s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9575084983003399, total=  29.1s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9569978498924946, total=  28.7s\n",
      "[CV] criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9574936240436065, total=  29.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.7700959808038392, total=   1.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.7677383869193459, total=   1.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.7533630044506676, total=   1.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.7982403519296141, total=   2.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.8148907445372269, total=   2.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.7990198529779466, total=   2.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.8397320535892822, total=   5.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.8307415370768538, total=   4.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.8295744361654248, total=   5.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8581783643271346, total=  12.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8421921096054803, total=  12.4s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.8424263639545931, total=  12.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.7566486702659468, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.7570878543927196, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.7732159823973596, total=   1.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.8124875024995001, total=   2.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.7829891494574729, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.8161224183627545, total=   2.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.8382323535292941, total=   5.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.8413920696034801, total=   5.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.8291743761564234, total=   4.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.8487302539492102, total=  11.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.8445422271113555, total=  11.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.8469770465569836, total=  12.8s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.7699460107978404, total=   1.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.7484374218710935, total=   1.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.7540131019652948, total=   1.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.8065386922615477, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.8090904545227261, total=   2.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.7958193729059359, total=   2.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.8370325934813038, total=   5.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.8246912345617281, total=   5.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.8357753663049458, total=   5.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8492301539692062, total=  11.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8415920796039802, total=  13.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.8422763414512177, total=  13.1s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.7258548290341932, total=   1.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.7584379218960948, total=   1.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.750212531879782, total=   1.5s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.8086382723455309, total=   2.9s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.8075903795189759, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.8217232584887734, total=   2.7s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.836882623475305, total=   6.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.8346417320866043, total=   5.6s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.827274091113667, total=   5.2s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.8474805038992201, total=  12.8s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.8488924446222311, total=  13.0s\n",
      "[CV] criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=5, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.8422263339500925, total=  13.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9053689262147571, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9023951197559879, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9014852227834175, total=   3.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9272145570885822, total=   5.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9263963198159908, total=   6.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9272390858628794, total=   5.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9375124975004999, total=  11.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9388969448472424, total=  11.6s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9388908336250438, total=  11.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9446110777844431, total=  24.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9453972698634932, total=  24.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9434415162274341, total=  25.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9043691261747651, total=   3.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9052952647632382, total=   3.8s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.901335200280042, total=   3.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9289642071585683, total=   6.2s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9289964498224911, total=   5.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9252387858178727, total=   4.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9367626474705059, total=   9.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9392969648482424, total=  10.8s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9362404360654099, total=  11.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9456608678264347, total=  27.2s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9451972598629932, total=  26.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9434915237285593, total=  26.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9081683663267347, total=   2.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9047452372618631, total=   2.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.90518577786668, total=   2.8s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9273645270945811, total=   5.7s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9250962548127406, total=   6.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9232384857728659, total=   5.9s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9374625074985004, total=  12.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9379468973448672, total=  10.8s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9366404960744111, total=  11.0s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9436112777444511, total=  26.2s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9436471823591179, total=  27.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9430414562184327, total=  24.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9080183963207359, total=   2.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.903445172258613, total=   2.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.8992848927339101, total=   2.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9319636072785443, total=   5.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.928196409820491, total=   5.3s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9282392358853828, total=   5.5s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9379624075184964, total=  11.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.936696834841742, total=  11.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9368405260789119, total=  11.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9443611277744451, total=  27.1s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9436971848592429, total=  26.4s\n",
      "[CV] criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=10, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9449917487623144, total=  24.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9173165366926614, total=   3.5s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9186959347967398, total=   3.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=5, score=0.9117367605140771, total=   3.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9454109178164367, total=   7.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9404470223511175, total=   6.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=10, score=0.9425913887083063, total=   7.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9560587882423516, total=  13.1s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9555477773888694, total=  11.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=20, score=0.9540931139670951, total=  11.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9627074585082983, total=  32.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9613980699034952, total=  38.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=2, n_estimators=50, score=0.9594439165874882, total=  33.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9228154369126175, total=   5.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9182459122956148, total=   3.5s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=5, score=0.9153873080962144, total=   3.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9441611677664468, total=   7.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9407470373518676, total=   7.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=10, score=0.9433415012251838, total=   7.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9548590281943611, total=  15.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9532476623831192, total=  14.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=20, score=0.9543431514727209, total=   9.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.962757448510298, total=  28.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9594979748987449, total=  38.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=1, min_samples_split=5, n_estimators=50, score=0.9613442016302446, total=  38.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9230653869226155, total=   4.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9187459372968648, total=   3.5s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=5, score=0.9194379156873531, total=   3.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9423115376924615, total=   6.8s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9393469673483674, total=   6.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=10, score=0.9420913136970546, total=   6.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9519096180763847, total=  13.2s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9501475073753688, total=  11.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=20, score=0.9500925138770816, total=  12.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.958258348330334, total=  30.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9548477423871193, total=  30.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50, score=0.9571935790368555, total=  25.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.921865626874625, total=   3.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9172958647932397, total=   3.4s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=5, score=0.9190878631794769, total=   3.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9427114577084583, total=   6.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9407470373518676, total=   6.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=10, score=0.9398409761464219, total=   6.3s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9507598480303939, total=  12.9s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9504975248762438, total=  12.6s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=20, score=0.9497424613692054, total=  12.5s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9575084983003399, total=  31.0s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9561978098904945, total=  30.7s\n",
      "[CV] criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50 \n",
      "[CV]  criterion=entropy, max_depth=15, min_samples_leaf=5, min_samples_split=5, n_estimators=50, score=0.9556933540031005, total=  31.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 384 out of 384 | elapsed: 65.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [5, 10, 20, 50], 'criterion': ['gini', 'entropy'], 'min_samples_split': [2, 5], 'max_depth': [None, 5, 10, 15], 'min_samples_leaf': [1, 5]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo parâmetros para Decision Trees\n",
    "param_grid_forest = [\n",
    "    {\n",
    "        'n_estimators': [5, 10, 20, 50],        \n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_leaf': [1, 5],\n",
    "        #'bootstrap': [True, False]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Criando classificador\n",
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "# Treinando e procurando a melhor combinação\n",
    "grid_search = GridSearchCV(forest_clf, param_grid_forest, cv=3, \n",
    "                           scoring='accuracy', verbose=3)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:32:19.311503Z",
     "start_time": "2019-01-07T19:32:19.299617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632166666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando melhor score\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muito interessante. Vamos verificar qual a melhor combinação de hiperparâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:32:59.047473Z",
     "start_time": "2019-01-07T19:32:59.039313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 50}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhor combinação de hiperparâmetros\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:33:31.605681Z",
     "start_time": "2019-01-07T19:33:31.596986Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_train': 0.999, 'acc_train_cv': 0.941, 'acc_train_scaled': 0.9406}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando o que temos até o momento\n",
    "dict_accs_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:33:42.980692Z",
     "start_time": "2019-01-07T19:33:42.949573Z"
    }
   },
   "source": [
    "### Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:35:07.799570Z",
     "start_time": "2019-01-07T19:34:59.102761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo Random Forest nos dados de teste: 0.9480\n"
     ]
    }
   ],
   "source": [
    "# Verificando Acurácia (simples)\n",
    "forest.fit(X_train, y_train)\n",
    "pred_test = forest.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "print(f'Acurácia do modelo Random Forest nos dados de teste: {acc_test:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_test'] = round(acc_test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muito interessante! O modelo Random Forest tem os ingredientes necessários para se tornar um excelente modelo para o problema em questão. Continuando as análises..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:37:49.601153Z",
     "start_time": "2019-01-07T19:37:38.541788Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo após padronização: 0.9251\n"
     ]
    }
   ],
   "source": [
    "# Verificando sensibilidade a dados padronizados\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "# Treinando novo modelo e realizando predições\n",
    "forest.fit(X_train_scaled, y_train)\n",
    "pred_scaled = forest.predict(X_test_scaled)\n",
    "\n",
    "# Acurácia após padronização\n",
    "acc_scaled = accuracy_score(y_test, pred_scaled)\n",
    "print(f'Acurácia do modelo após padronização: {acc_scaled:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_test_scaled'] = round(acc_scaled, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como já mencionado anteriormente, o modelo ```Random Forest``` não é sensível à padronização dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:41:56.899005Z",
     "start_time": "2019-01-07T19:41:11.700231Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo após GridSearchCV: 0.9668\n"
     ]
    }
   ],
   "source": [
    "# Verificando acurácia com o melhor modelo obtido através da busca Grid Search\n",
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "# Treinando modelo e verificando performance\n",
    "final_model.fit(X_train, y_train)\n",
    "pred_grid = final_model.predict(X_test)\n",
    "acc_grid = accuracy_score(y_test, pred_grid)\n",
    "print(f'Acurácia do modelo após GridSearchCV: {acc_grid:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_test_grid'] = round(acc_grid, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma acurácia muito boa! Aprox 0.2% melhor que a versão sem tratamento. Será que ainda há espaço para melhoria?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:43:57.675977Z",
     "start_time": "2019-01-07T19:43:04.436864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retornando dados aprimorados\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:43:57.692527Z",
     "start_time": "2019-01-07T19:43:57.679977Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_train_augmented: (300000, 784)\n",
      "Dimensões de y_train_augmented: (300000,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando novas dimensões\n",
    "print(f'Dimensões de X_train_augmented: {X_train_augmented.shape}')\n",
    "print(f'Dimensões de y_train_augmented: {y_train_augmented.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:44:26.683333Z",
     "start_time": "2019-01-07T19:44:26.171102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d03093e9b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando dígitos\n",
    "plot_data_augmented(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:51:04.300055Z",
     "start_time": "2019-01-07T19:46:10.424850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia após deslocamento de pixels nos dados: 0.9794\n"
     ]
    }
   ],
   "source": [
    "# Realizando um último treinamento\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Predizendo e verificando acurácia\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Acurácia após deslocamento de pixels nos dados: {y_acc:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_forest['acc_test_shifted'] = round(y_acc, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma melhoria de 1%! Com isto, chegamos em incríveis 97,9% de acurácia final do modelo nos dados de teste! Realmente o modelo ```Random Forest``` se mostrou muito poderoso para classificação dos dados do MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:51:04.521051Z",
     "start_time": "2019-01-07T19:51:04.303421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0     1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "1     0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "2     0.9990        0.9410            0.9406    0.9480           0.9251   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0         0.8890            0.9211  \n",
       "1         0.9139            0.8532  \n",
       "2         0.9668            0.9794  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando dados para o modelo Random Forest e verificando resultados\n",
    "dataset_accs = dataset_accs.append(dict_accs_forest, ignore_index=True)\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-07T19:52:40.112409Z",
     "start_time": "2019-01-07T19:52:40.073329Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando em arquivo\n",
    "save_dataset(dataset_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:56:54.282074Z",
     "start_time": "2019-01-17T21:56:51.269693Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparando dados\n",
    "X_train, y_train, X_test, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:56:54.301034Z",
     "start_time": "2019-01-17T21:56:54.283070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de X_train: (60000, 784)\n",
      "Dimensões de y_train: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Verificando dimensões\n",
    "print(f'Dimensões de X_train: {X_train.shape}')\n",
    "print(f'Dimensões de y_train: {y_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:56:57.136407Z",
     "start_time": "2019-01-17T21:56:54.316407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29374b85668>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando dígitos\n",
    "plot_mnist(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:56:57.578088Z",
     "start_time": "2019-01-17T21:56:57.140188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0     1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "1     0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "2     0.9990        0.9410            0.9406    0.9480           0.9251   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0         0.8890            0.9211  \n",
       "1         0.9139            0.8532  \n",
       "2         0.9668            0.9794  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resgatando performances até o momento\n",
    "dataset_accs = load_dataset()\n",
    "dict_accs_mlp = {}\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que:\n",
    "    - 0 = Decision Trees\n",
    "    - 1 = SGD Classifier\n",
    "    - 2 = Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T21:58:24.438206Z",
     "start_time": "2019-01-17T21:56:57.584421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo MLP nos dados de treino: 0.9833\n"
     ]
    }
   ],
   "source": [
    "# Criando classificador\n",
    "mlp_clf = MLPClassifier()\n",
    "\n",
    "# Treinando modelo e realizando predições\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "train_pred = mlp_clf.predict(X_train)\n",
    "\n",
    "# Verificando e comunicando acurácia\n",
    "acc_train = accuracy_score(y_train, train_pred)\n",
    "print(f'Acurácia do modelo MLP nos dados de treino: {acc_train:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_mlp['acc_train'] = round(acc_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponto a ser destacado:\n",
    "    - MLP possui um certo tempo de processamento relativamente maior que os demais.\n",
    "    - Possivalmente na validação cruzada esse tempo irá aumentar.\n",
    "    \n",
    "Buscando averiguar a presença de overfitting, vamos aplicar o processo de validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T22:00:31.172944Z",
     "start_time": "2019-01-17T21:58:24.441198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.93671266 0.94449722 0.94274141]\n",
      "Média: 0.9413\n",
      "Desvio Padrão: 0.0033\n"
     ]
    }
   ],
   "source": [
    "# Aplicando cross validation\n",
    "mlp_scores = cross_val_score(mlp_clf, X_train, y_train,\n",
    "                            cv=3, scoring='accuracy')\n",
    "display_scores(mlp_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T22:00:31.186946Z",
     "start_time": "2019-01-17T22:00:31.176262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando dados\n",
    "dict_accs_mlp['acc_train_cv'] = round(mlp_scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise:\n",
    "* O ```MLP``` apresentou uma alta acurácia no teste com os dados de treino, porém, diferente do que foi visto com o modelo ```RandomForest```, esta acurácia não chegou aos 99% (indicando um severo overfitting). Já na validação cruzada, os valores obtidos com o ```MLP```, apesar de terem sofrido um decréscimo com relação ao treinamento anterior, apresentaram valores superiores ao encontrado em ```RandomForest```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos se o MLP é sensível a padronização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T22:03:42.723662Z",
     "start_time": "2019-01-17T22:00:31.189560Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.97115577 0.96724836 0.96849527]\n",
      "Média: 0.9690\n",
      "Desvio Padrão: 0.0016\n"
     ]
    }
   ],
   "source": [
    "# Aplicando padronização dos dados\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "\n",
    "# Realizando um novo treinamento\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Novas predições com cross validation\n",
    "mlp_scaled_scores = cross_val_score(mlp_clf, X_train_scaled, y_train,\n",
    "                                   cv=3, scoring='accuracy')\n",
    "display_scores(mlp_scaled_scores)\n",
    "\n",
    "# Salvando dados\n",
    "dict_accs_mlp['acc_train_scaled'] = round(mlp_scaled_scores.mean(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T15:47:23.567819Z",
     "start_time": "2019-01-14T15:47:23.548769Z"
    }
   },
   "source": [
    "Houve melhora na performance do algoritmo (com os dados de treino) através da aplicação da padronização. Diferente do que se viu com ```DecisionTrees``` e ```RandomForest```, a padronização aplicada ao algoritmo de ```MLP``` gerou um acréscimo de aproximadamente 0.2% em acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T15:51:24.116594Z",
     "start_time": "2019-01-14T15:51:24.102390Z"
    }
   },
   "source": [
    "### Tunando Hiperparâmetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-14T15:51:53.044402Z",
     "start_time": "2019-01-14T15:51:53.038234Z"
    }
   },
   "source": [
    "Antes de aplicar o ```GridSearchCV``` para encontrar a melhor combinação de hiperparâmetros, é necessário entender quais são os hiperparâmetros do modelo ```MLP```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-01-17T00:56:07.416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hiperparâmetros do modelo\n",
    "mlp_clf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-17T23:05:53.363847Z",
     "start_time": "2019-01-17T22:03:42.725657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9679564087182564, total= 1.5min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9577978898944948, total= 1.0min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.6min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9659448917337601, total= 1.8min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9682563487302539, total= 1.3min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9581479073953698, total= 1.6min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9655948392258838, total= 2.0min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9680563887222555, total= 1.5min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9587979398969948, total= 1.5min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9655448317247587, total= 1.3min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9573585282943411, total= 1.6min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9568478423921196, total= 1.6min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.958193729059359, total= 1.4min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9559088182363528, total= 1.1min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9557977898894945, total= 1.0min\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9553433014952243, total=  52.7s\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9562087582483503, total=  42.6s\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9555477773888694, total=  52.1s\n",
      "[CV] activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9580937140571085, total=  40.2s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.965256948610278, total=  36.5s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9639481974098705, total=  52.4s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9660449067360104, total=  40.6s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9643571285742851, total=  40.1s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9634981749087455, total=  36.5s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9626944041606241, total=  37.0s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9686062787442512, total=  48.6s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9630981549077454, total=  38.9s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9658948842326349, total=  47.2s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9473105378924215, total=  36.8s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9493974698734937, total=  38.0s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9446917037555633, total=  26.9s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9473105378924215, total=  32.8s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9432471623581179, total=  36.2s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9415912386858029, total=  39.3s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9467606478704259, total=  27.6s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9408470423521176, total=  42.7s\n",
      "[CV] activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9454418162724408, total=  28.7s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9624575084983004, total=  42.0s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9613980699034952, total=  38.4s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9630444566685002, total=  36.5s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9625574885022995, total=  42.2s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9597979898994949, total=  38.6s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9611441716257438, total=  38.3s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9599080183963208, total=  42.2s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9586979348967448, total=  38.9s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9607941191178677, total=  37.3s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9422115576884623, total=  26.6s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9407970398519926, total=  30.1s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9431914787218083, total=  33.1s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9391121775644871, total=  31.0s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.935696784839242, total=  23.8s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.944891733760064, total=  31.7s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9425114977004599, total=  29.2s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9368968448422421, total=  31.3s\n",
      "[CV] activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=logistic, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9381907286092914, total=  32.1s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9708058388322336, total=  22.5s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.967848392419621, total=  25.7s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9699454918237735, total=  13.2s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9717556488702259, total=  19.8s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9683484174208711, total=  23.8s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9691453718057709, total=  24.4s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9726054789042191, total=  20.5s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9715485774288715, total=  21.7s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9716457468620293, total=  20.5s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.964757048590282, total=  18.9s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9644482224111206, total=  16.7s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9648947342101315, total=  16.3s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9640071985602879, total=  15.2s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9614480724036202, total=   8.0s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9665949892483873, total=  18.8s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9685562887422515, total=  20.3s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9636481824091204, total=  16.8s\n",
      "[CV] activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.1, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9660449067360104, total=  18.4s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9608078384323135, total=  16.5s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9669983499174959, total=  18.0s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9701455218282743, total=  19.3s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9648570285942811, total=  17.2s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9683484174208711, total=  16.7s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9661949292393859, total=  14.3s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9667566486702659, total=  14.7s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9640482024101205, total=  12.4s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9663449517427614, total=  16.7s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9647070585882823, total=  16.3s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9589479473973699, total=  20.0s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9588438265739861, total=  17.6s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9649570085982804, total=  14.8s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9637481874093705, total=  16.1s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9609441416212432, total=  13.4s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.960757848430314, total=  17.3s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9615980799039952, total=  13.5s\n",
      "[CV] activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.01, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9645946892033805, total=  13.6s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9729554089182163, total=  23.7s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9571478573928697, total=  20.0s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=constant, score=0.9726959043856579, total=  22.8s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9655568886222755, total=  16.4s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9665483274163709, total=  16.9s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=invscaling, score=0.9713957093564035, total=  24.2s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9680563887222555, total=  17.5s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9665983299164959, total=  13.4s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(100, 100), learning_rate=adaptive, score=0.9636945541831274, total=  15.9s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9629574085182964, total=  14.4s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9555477773888694, total=  15.1s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=constant, score=0.9607441116167426, total=  13.3s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9616076784643072, total=  13.7s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.96044802240112, total=  15.2s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=invscaling, score=0.9612441866279942, total=  12.4s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9595080983803239, total=  14.5s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.9572478623931197, total=  16.2s\n",
      "[CV] activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive \n",
      "[CV]  activation=relu, alpha=0.001, hidden_layer_sizes=(50, 50, 50), learning_rate=adaptive, score=0.960894134120118, total=  15.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 108 out of 108 | elapsed: 61.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': ['constant', 'invscaling', 'adaptive'], 'hidden_layer_sizes': [(100, 100), (50, 50, 50)], 'alpha': [0.1, 0.01, 0.001], 'activation': ['logistic', 'relu']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Considerando alguns parâmetros para a rede\n",
    "params = {\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'hidden_layer_sizes': [(100, 100), (50, 50, 50)],\n",
    "    'alpha': [0.1, 0.01, 0.001],\n",
    "    'activation': ['logistic', 'relu']\n",
    "}\n",
    "\n",
    "# Aplicando GridSearch\n",
    "mlp_clf = MLPClassifier()\n",
    "grid_search = GridSearchCV(mlp_clf, params, cv=3,\n",
    "                          scoring='accuracy', verbose=3)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:05:39.184455Z",
     "start_time": "2019-01-18T01:05:39.137392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'alpha': 0.1,\n",
       " 'hidden_layer_sizes': (100, 100),\n",
       " 'learning_rate': 'adaptive'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando os melhores parâmetros\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:05:58.954714Z",
     "start_time": "2019-01-18T01:05:58.842041Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9719333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a melhor acurácia\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um número levemente superior ao encontrado a partir dos dados padronizados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dados de Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:06:57.499559Z",
     "start_time": "2019-01-18T01:06:57.493575Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_train': 0.9834, 'acc_train_cv': 0.9413, 'acc_train_scaled': 0.969}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando scores até o momento\n",
    "dict_accs_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:07:33.783229Z",
     "start_time": "2019-01-18T01:07:33.654537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0     1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "1     0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "2     0.9990        0.9410            0.9406    0.9480           0.9251   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0         0.8890            0.9211  \n",
       "1         0.9139            0.8532  \n",
       "2         0.9668            0.9794  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparando com os demais modelos\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:10:40.083383Z",
     "start_time": "2019-01-18T01:09:52.934193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia de MLP Classifier nos dados de teste: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Treinando nos dados de teste\n",
    "mlp_clf = MLPClassifier()\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# Verificando acurácia\n",
    "test_pred = mlp_clf.predict(X_test)\n",
    "acc_test = accuracy_score(y_test, test_pred)\n",
    "\n",
    "print(f'Acurácia de MLP Classifier nos dados de teste: {acc_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:10:50.289308Z",
     "start_time": "2019-01-18T01:10:50.261386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando dados\n",
    "dict_accs_mlp['acc_test'] = round(acc_test, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:13:07.125891Z",
     "start_time": "2019-01-18T01:12:21.595815Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thiagoPanini\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia com padronização dos dados: 0.9734\n"
     ]
    }
   ],
   "source": [
    "# Aplicando padronização\n",
    "X_train_scaled, X_test_scaled = data_scaled(X_train, X_test)\n",
    "mlp_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "test_pred_scaled = mlp_clf.predict(X_test_scaled)\n",
    "acc_test_scaled = accuracy_score(y_test, test_pred_scaled)\n",
    "\n",
    "print(f'Acurácia com padronização dos dados: {acc_test_scaled:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:18:44.588132Z",
     "start_time": "2019-01-18T01:18:44.584142Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando dados\n",
    "dict_accs_mlp['acc_test_scaled'] = round(acc_test_scaled, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ganho considerável em se tratando de dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:15:34.984222Z",
     "start_time": "2019-01-18T01:15:00.618705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia nos dados de teste após GridSearchCV: 0.9733\n"
     ]
    }
   ],
   "source": [
    "# Verificando acurácia com melhor modelo retornado pelo GridSearch\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "test_pred_grid = final_model.predict(X_test_scaled)\n",
    "acc_test_grid = accuracy_score(y_test, test_pred_grid)\n",
    "\n",
    "print(f'Acurácia nos dados de teste após GridSearchCV: {acc_test_grid:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:18:19.238672Z",
     "start_time": "2019-01-18T01:18:19.233685Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando resultado\n",
    "dict_accs_mlp['acc_test_grid'] = round(acc_test_grid, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não houve ganhos consideráveis de acurácia comparando com o resultado anterior (apenas padronização). Vamos aplicar agora o conceito de data augmentation para uma última tentativa de melhoria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:17:19.420243Z",
     "start_time": "2019-01-18T01:16:50.909320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retornando dados aprimorados\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:17:21.646117Z",
     "start_time": "2019-01-18T01:17:21.641131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões após alterações: (300000, 784)\n"
     ]
    }
   ],
   "source": [
    "# Verificando novas dimensões\n",
    "print(f'Dimensões após alterações: {X_train_augmented.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:17:36.230228Z",
     "start_time": "2019-01-18T01:17:35.197565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x29300421e48>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotando dígitos\n",
    "plot_data_augmented(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:33:40.894585Z",
     "start_time": "2019-01-18T01:27:00.609326Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia após deslocamento de pixels nos dados: 0.9826\n"
     ]
    }
   ],
   "source": [
    "# Realizando um último treinamento\n",
    "final_model = grid_search.best_estimator_\n",
    "final_model.fit(X_train_augmented, y_train_augmented)\n",
    "\n",
    "# Predizendo e verificando acurácia\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Acurácia após deslocamento de pixels nos dados: {y_acc:.4f}')\n",
    "\n",
    "# Salvando resultados\n",
    "dict_accs_mlp['acc_test_shifted'] = round(y_acc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:50:18.666113Z",
     "start_time": "2019-01-18T01:50:18.506271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "0     1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "1     0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "2     0.9990        0.9410            0.9406    0.9480           0.9251   \n",
       "3     0.9834        0.9413            0.9690    0.9599           0.9734   \n",
       "\n",
       "   acc_test_grid  acc_test_shifted  \n",
       "0         0.8890            0.9211  \n",
       "1         0.9139            0.8532  \n",
       "2         0.9668            0.9794  \n",
       "3         0.9733            0.9826  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvando dados para o modelo Random Forest e verificando resultados\n",
    "dataset_accs = dataset_accs.append(dict_accs_mlp, ignore_index=True)\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que:\n",
    "    - 0 = Decision Trees\n",
    "    - 1 = SGD Classifier\n",
    "    - 2 = Random Forest\n",
    "    - 3 = Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:51:41.831179Z",
     "start_time": "2019-01-18T01:51:41.805250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Salvando dataset\n",
    "save_dataset(dataset_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:53:28.408700Z",
     "start_time": "2019-01-18T01:53:28.389778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_train_cv</th>\n",
       "      <th>acc_train_scaled</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>acc_test_scaled</th>\n",
       "      <th>acc_test_grid</th>\n",
       "      <th>acc_test_shifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtree</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6226</td>\n",
       "      <td>0.8890</td>\n",
       "      <td>0.9211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.8825</td>\n",
       "      <td>0.8678</td>\n",
       "      <td>0.9101</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>0.8532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forest</th>\n",
       "      <td>0.9990</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.9668</td>\n",
       "      <td>0.9794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp</th>\n",
       "      <td>0.9834</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.9826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc_train  acc_train_cv  acc_train_scaled  acc_test  acc_test_scaled  \\\n",
       "dtree      1.0000        0.8617            0.8604    0.8800           0.6226   \n",
       "sgd        0.8825        0.8678            0.9101    0.8841           0.9139   \n",
       "forest     0.9990        0.9410            0.9406    0.9480           0.9251   \n",
       "mlp        0.9834        0.9413            0.9690    0.9599           0.9734   \n",
       "\n",
       "        acc_test_grid  acc_test_shifted  \n",
       "dtree          0.8890            0.9211  \n",
       "sgd            0.9139            0.8532  \n",
       "forest         0.9668            0.9794  \n",
       "mlp            0.9733            0.9826  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lendo novamente dataset\n",
    "dataset_accs = load_dataset()\n",
    "models = ['dtree', 'sgd', 'forest', 'mlp']\n",
    "dataset_accs.index = models\n",
    "dataset_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-18T01:58:35.657064Z",
     "start_time": "2019-01-18T01:58:35.623154Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test results: dtree ---\n",
      "acc_test            0.8800\n",
      "acc_test_scaled     0.6226\n",
      "acc_test_grid       0.8890\n",
      "acc_test_shifted    0.9211\n",
      "Name: dtree, dtype: float64\n",
      "\n",
      "--- Test results: sgd ---\n",
      "acc_test            0.8841\n",
      "acc_test_scaled     0.9139\n",
      "acc_test_grid       0.9139\n",
      "acc_test_shifted    0.8532\n",
      "Name: sgd, dtype: float64\n",
      "\n",
      "--- Test results: forest ---\n",
      "acc_test            0.9480\n",
      "acc_test_scaled     0.9251\n",
      "acc_test_grid       0.9668\n",
      "acc_test_shifted    0.9794\n",
      "Name: forest, dtype: float64\n",
      "\n",
      "--- Test results: mlp ---\n",
      "acc_test            0.9599\n",
      "acc_test_scaled     0.9734\n",
      "acc_test_grid       0.9733\n",
      "acc_test_shifted    0.9826\n",
      "Name: mlp, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    print(f'\\n--- Test results: {models[i]} ---')\n",
    "    print(dataset_accs.iloc[i, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após os diversos testes realizados, foi possível concluir que o algorítmo de Redes Neurais Multi Layer Perceptron (```MLP Classifier```) apresentou os melhores resultados treinado com o dataset MNIST. \n",
    "\n",
    "Mesmo com um tempo de processamento um pouco mais elevado que os demais, fato este agravado pela adição de uma camada oculta indicada pelo ```GridSearchCV```, os resultados obtidos nos dados de teste apresentaram ótimas performances, auxiliadas também pelo aumento do dataset através do deslocamento de pixels.\n",
    "\n",
    "Em segundo plano, vale destacar a performance do algoritmo ```RandomForest``` que, por sua vez, provou porque é tão famoso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "399px",
    "left": "709px",
    "top": "111.36px",
    "width": "243px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
