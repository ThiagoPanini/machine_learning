{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando a função ```fminunc``` para encontrar os melhores parâmetros de função hypothesis, dada sua respectiva função de custo ```J(theta)``` e as derivadas parciais do gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo função preparatório para entrada no fminunc\n",
    "\n",
    "function [jVal, gradient] = costFunction(theta)\n",
    "    % -------------------------------------------------\n",
    "    % Description\n",
    "    % -------------------------------------------------\n",
    "    % INPUT:\n",
    "    %    theta -> vetor \"n\" dimensional contendo todos os parâmetros theta_1, ... theta_n\n",
    "    %\n",
    "    % OUTPUT:\n",
    "    %    jVal -> definição da função de custo relacionada aos parâmetros theta fornecidos\n",
    "    %    gradient -> definição(ões) de cada uma das derivadas parciais presentes (Gradient Descent)\n",
    "    %\n",
    "    % -------------------------------------------------\n",
    "    % Corpo da Função\n",
    "    % -------------------------------------------------\n",
    "    \n",
    "    jVal = (theta(1)-5)^2 + (theta(2)-5)^2;\n",
    "    gradient = zeros(size(theta), 1);\n",
    "    \n",
    "    gradient(1) = 2*(theta(1)-5);\n",
    "    gradient(2) = 2*(theta(2)-5);\n",
    "    \n",
    "endfunction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optTheta =\n",
      "\n",
      "   5.0000\n",
      "   5.0000\n",
      "\n",
      "functionVal =    1.5777e-30\n",
      "exitFlag =  1\n"
     ]
    }
   ],
   "source": [
    "# Chamando função fminunc para otimização dos parâmetros\n",
    "options = optimset('GradObj', 'on', 'MaxIter', 100);\n",
    "initialTheta = zeros(2, 1);\n",
    "[optTheta, functionVal, exitFlag] = fminunc(@costFunction, initialTheta, options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultados:\n",
    "    - optTheta = melhores parâmetros para resolução do problema (theta(1) = 5 e theta(2) = 5);\n",
    "    - functionVal = valor da função de custo. Neste caso, virtualmente é zero pois os parâmetros se encaixam perfeitamente;\n",
    "    - exitFlag = flag que indica o sucesso ou não da função fminunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'fminunc' is a function from the file C:\\Octave\\Octave-4.4.1\\share\\octave\\4.4.1\\m\\optimization\\fminunc.m\n",
      "\n",
      " -- fminunc (FCN, X0)\n",
      " -- fminunc (FCN, X0, OPTIONS)\n",
      " -- [X, FVAL, INFO, OUTPUT, GRAD, HESS] = fminunc (FCN, ...)\n",
      "     Solve an unconstrained optimization problem defined by the function\n",
      "     FCN.\n",
      "\n",
      "     FCN should accept a vector (array) defining the unknown variables,\n",
      "     and return the objective function value, optionally with gradient.\n",
      "     'fminunc' attempts to determine a vector X such that 'FCN (X)' is a\n",
      "     local minimum.\n",
      "\n",
      "     X0 determines a starting guess.  The shape of X0 is preserved in\n",
      "     all calls to FCN, but otherwise is treated as a column vector.\n",
      "\n",
      "     OPTIONS is a structure specifying additional options.  Currently,\n",
      "     'fminunc' recognizes these options: \"FunValCheck\", \"OutputFcn\",\n",
      "     \"TolX\", \"TolFun\", \"MaxIter\", \"MaxFunEvals\", \"GradObj\",\n",
      "     \"FinDiffType\", \"TypicalX\", \"AutoScaling\".\n",
      "\n",
      "     If \"GradObj\" is \"on\", it specifies that FCN, when called with two\n",
      "     output arguments, also returns the Jacobian matrix of partial first\n",
      "     derivatives at the requested point.  'TolX' specifies the\n",
      "     termination tolerance for the unknown variables X, while 'TolFun'\n",
      "     is a tolerance for the objective function value FVAL.  The default\n",
      "     is '1e-7' for both options.\n",
      "\n",
      "     For a description of the other options, see 'optimset'.\n",
      "\n",
      "     On return, X is the location of the minimum and FVAL contains the\n",
      "     value of the objective function at X.\n",
      "\n",
      "     INFO may be one of the following values:\n",
      "\n",
      "     1\n",
      "          Converged to a solution point.  Relative gradient error is\n",
      "          less than specified by 'TolFun'.\n",
      "\n",
      "     2\n",
      "          Last relative step size was less than 'TolX'.\n",
      "\n",
      "     3\n",
      "          Last relative change in function value was less than 'TolFun'.\n",
      "\n",
      "     0\n",
      "          Iteration limit exceeded--either maximum number of algorithm\n",
      "          iterations 'MaxIter' or maximum number of function evaluations\n",
      "          'MaxFunEvals'.\n",
      "\n",
      "     -1\n",
      "          Algorithm terminated by 'OutputFcn'.\n",
      "\n",
      "     -3\n",
      "          The trust region radius became excessively small.\n",
      "\n",
      "     Optionally, 'fminunc' can return a structure with convergence\n",
      "     statistics (OUTPUT), the output gradient (GRAD) at the solution X,\n",
      "     and approximate Hessian (HESS) at the solution X.\n",
      "\n",
      "     Application Notes: If the objective function is a single nonlinear\n",
      "     equation of one variable then using 'fminbnd' is usually a better\n",
      "     choice.\n",
      "\n",
      "     The algorithm used by 'fminunc' is a gradient search which depends\n",
      "     on the objective function being differentiable.  If the function\n",
      "     has discontinuities it may be better to use a derivative-free\n",
      "     algorithm such as 'fminsearch'.\n",
      "\n",
      "     See also: fminbnd, fminsearch, optimset.\n",
      "\n",
      "Additional help for built-in functions and operators is\n",
      "available in the online version of the manual.  Use the command\n",
      "'doc <topic>' to search the manual index.\n",
      "\n",
      "Help and information about Octave is also available on the WWW\n",
      "at https://www.octave.org and via the help@octave.org\n",
      "mailing list.\n"
     ]
    }
   ],
   "source": [
    "# Pedindo ajuda\n",
    "help fminunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.4.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
