{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Exercício-1\" data-toc-modified-id=\"Exercício-1-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Exercício 1</a></span></li><li><span><a href=\"#Exercício-2\" data-toc-modified-id=\"Exercício-2-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Exercício 2</a></span></li><li><span><a href=\"#Exercício-3\" data-toc-modified-id=\"Exercício-3-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exercício 3</a></span></li><li><span><a href=\"#Exercício-4\" data-toc-modified-id=\"Exercício-4-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exercício 4</a></span></li><li><span><a href=\"#Exercício-5\" data-toc-modified-id=\"Exercício-5-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exercício 5</a></span></li><li><span><a href=\"#Exercício-6\" data-toc-modified-id=\"Exercício-6-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Exercício 6</a></span></li><li><span><a href=\"#Exercício-7\" data-toc-modified-id=\"Exercício-7-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Exercício 7</a></span></li><li><span><a href=\"#Exercício-8\" data-toc-modified-id=\"Exercício-8-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Exercício 8</a></span></li><li><span><a href=\"#Exercício-9\" data-toc-modified-id=\"Exercício-9-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Exercício 9</a></span></li><li><span><a href=\"#Exercício-10\" data-toc-modified-id=\"Exercício-10-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Exercício 10</a></span></li><li><span><a href=\"#Exercício-11\" data-toc-modified-id=\"Exercício-11-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Exercício 11</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_What Linear Regression training algorithm can you use if you have a training set with millions of features?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Com milhões de features, uma restrição que se faz presente é a utilização da `Normal Equation`, uma vez que esta envolve a inversão de matrizes de dimensões dependentes do número de features, se tornando um processo computacionalmente inviável (muito complexo) a medida que esta dimensão cresce. Dessa forma, `Stochastic Gradient Descent`, `Mini Batch Gradient Descent` ou, quem sabe, `Batch Gradient Descent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Suppose the features in your training set have very different scales. What algorithms might suffer from this, and how? What can you do about ir?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: A grande maioria dos algoritmos poderá ser afetado com a diferença na escala das features. Tal diferença afeta o gradiente no sentido de dificultar o alcance do mínimo global (imagine um dos eixos como uma elipse mais achatada), necessitando de um número maior de iterações, dado que os parâmetros vinculados as features de maior range (máximo e mínimo) são mais sensíveis a alterações em suas magnitudes.\n",
    "\n",
    "Para evitar que isto ocorra, é possível normalizar os dados através da classe `StandardScaler` oferecida pelo sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Can Gradient Descent get stuck in a local minimum when training a Logistic Regression model?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Não. Assim como em modelos de Regressão Linear, modelos de Regressão Logística possuem uma função custo com um shape convexo, ou seja, possuindo apenas um mínimo local (e global ao mesmo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Do all Gradient Descent algorithms lead to the same model provided you let them run long enough?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Não. Existe um parâmetro que influencia diretamente no comportamento do gradiente rumo ao mínimo global: `learning rate` (ou $\\alpha$). O parâmetro de regularizaçao $\\alpha$ tem a responsabilidade de fornecer ao modelo a magnitude da regularização aplicada ao treinamento, ou seja, seu valor pode fazer com que o gradiente alcance o mínimo global de forma mais lenta, mais rápida, ou até mesmo fazer com que a função não alcance o mínimo global, divergindo assim do resultado esperado.\n",
    "\n",
    "Imagine o fator $\\alpha$ como sendo o tamanho do passo dado rumo ao alcance do mínimo local. Se este passo for muito curto, o modelo irá levar mais tempo para alcançar o objetivo. Se este passo for muito longo, há o risco do modelo não convergir, dado que, a cada iteração, a distância entre o ponto atual e o mínimo aumenta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supondo uma situação ideal: $\\alpha$ configurado adequadamente.\n",
    "\n",
    "Mesmo que o fator de regularização não esteja tão elevado e, se tratando de Regressões Lineares e Logísticas (funções custo convexas), ainda sim não é possível afirmar que todos os algoritmos cheguem ao mesmo ponto em um longo período de tempo. Isto pois os algoritmos `Stochastic GD` e `Mini-Batch GD`, por suas funcionalidades, não seguem um caminho linear rumo ao mínimo, mas sim apresentam uma pequena oscilação próxima a região ótima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Suppose you use Batch Gradient Descent and you plot the validation error at every epoch. If you notice that the validation error consistently goes up, what is likely going on? How you can fix it?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa situação, é possível concluir que o modelo sofre de `overfitting`, ou seja, o modelo se enquadra tão bem nos dados de treino que, ao ser apresentado aos dados de validação, resulta consideráveis erros. Isto indica uma falta de `generalização` do modelo e pode estar vinculado aos seguintes fatores:\n",
    "* Alto grau polinomial;\n",
    "* Muitas features presentes;\n",
    "* Baixo fator de regularização alpha.\n",
    "    \n",
    "Para tentar amenizar estes erros, seria possível:\n",
    "* Diminuir o grau polinomial;\n",
    "* Aumentar o fator de regularização alpha;\n",
    "* Aplicar um procedimento de feature selection para manter apenas as features mais importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Is it a good idea to stop Mini-batch Gradient Descent immediately when the validation error goes up?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Não. A parada imediata deste gradiente assim que o erro de validação cresce é um equívoco e pode ocasionar performances não esperadas. Neste caso, o ideal seria continuar o treinamento por mais algumas iterações para realmente se certificar de que a performance não pode ser melhorada. Neste momento, então, o treinamento pode ser parado. A própria natureza randomica dos algoritmos Mini-batch GD e Stochastic GD fazem com que os erros oscilem um pouco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tecnicamente, é possível salvar os melhores resultados gradativamente para que, quando o modelo não superar o melhor resultado depois de um longo período de tempo, seja possível retornar ao momento onde o modelo alcançou o melhor resultado e considerar os parâmetros obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which Gradient Descent algorithm (among those we discussed) will reach the vicinity of the optimal solution fastes? Which will actually converge? How can you make the others converge as well?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo GD que irá alcançar a vizinhança ótima de maneira mais rápida é o `Stochastic Gradient Descent`. Isto pois sua natureza de aplicação indica a utilização de apenas uma amostra a cada iteração, sendo esta escolhida aleatoriamente.\n",
    "\n",
    "O algoritmo que realmente irá convergir é o `Batch Gradient Descent`, dado que este considera todo o conjunto de dados a cada iteração e atualização dos parâmetros theta. Por este mesmo motivo, o Batch GD irá levar um tempo maior para alcançar o mínimo global.\n",
    "\n",
    "Para fazer com que todos os algoritmos alcancem o mínimo global (ou pelo menos chegarem o mais próximo possível), pode-se diminuir gradativamente o parâmetro de `regularização` $alpha$. Com isto, mesmo os modelos vinculados a um alicerce randomico (Stochastic GD e Mini-Batch GD) irão apresentar oscilações muito próximas de zero, fazendo com que estes alcancem valores extremamente próximos do mínimo global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Suppose you are using Polynomial Regression. You plot the learning curves and you notice that there is a large gap between the traning error and the validation error. What is happening? What are three ways to solve this?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: A partir das curvas de aprendizado, é possível retirar conclusões extremamente importantes sobre o modelo. A grande diferença (gap) entre o erro de treino e o erro de validação indica que o modelo sofre de `overfitting`. Como mencionado no exercício 5, este tipo de fenômeno ocorre quando o modelo se enquadra tão bem nos dados de treino que perde poder de generalização, apresentando resultados ruins quando submetido a dados externos ao treinamento (validação e treino). Para mitigar o overfitting, é possível:\n",
    "* Diminuir o grau polinomial do modelo;\n",
    "* Aumentar o parâmetro de regularização alpha;\n",
    "* Aumentar a quantidade de dados de treinamento;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Suppose you are using Ridge Regression and you notice that the traning error and the validation error are almost equal and fairly high. Would you say that the model suffers from high bias or high variance? Should you increase the regularization hyperparameter $\\alpha$ or reduce it?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Neste caso, o modelo sofre de `bias alto`, uma vez que tanto os dados de treino quanto os dados de validação apresentaram erros elevados. Em modelos com bias alto, aumentar o número de dados de treinamento não resolve o problema! Para aumentar a performance, é possível diminuir o parâmetro de regularização $\\alpha$, fazendo assim com que a magnitude dos parâmetros $\\theta$ vinculados aos altos graus polinomiais possam surtir um efeito positivo na curva relacionada ao modelo, diminuindo os erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Why would you want to use:_\n",
    "\n",
    "* _Ridge Regression instead of plain Linear Regression (i.e., without any regularization?)_\n",
    "* _Lasso instead of Ridge Regression?_\n",
    "* _Elastic Net instead of Lasso?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R:\n",
    "\n",
    "* 1. É preferível usar Ridge Regression em qualquer situação, dado que fatalmente os dados não irão se comportar exatamente como uma curva linear, necessitando assim de alguma regularização.\n",
    "\n",
    "* 2. Lasso é preferível a Ridge Regression sempre que houver a suspeita de que algumas features não são tão úteis ao modelo. Isto pois, devido a penalização $l_1$ do algoritmo Lasso Regression, magnitudes de parâmetros ligados a features menos importantes tendem a zero, ou seja, esta regularização tende a eliminar tais features.\n",
    "\n",
    "* 3. Neste caso, é preferível utiliar o algoritmo Elastic Net quando o número de features do modelo superar (ou chegar bem próximo) o número de dados de treinamento. Isto pois o algoritmo Lasso tende a se comportar de maneira inadequada quando o número de features ultrapassa os dados de treinamento. Também é preferível Elatic Net quando existem muitas features correlacionadas. Além disso, é possível utilizar Elastic Net com o hyperparâmetro l1_ratio próximo de 1 (configuração próxima ao Lasso)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Suppose you want to classify pictures as outdoor/indoor and daytime/nighttime. Should you implement two Logistic Regression classifiers or one Softmax Regression Classifier?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R: Neste caso, é importante lembrar que `Softmax Regression` é um modoelo de classificação multilabel e não multioutput. Para o problema proposto, temos duas situações diferentes, ou melhor, dois resultados diferentes para 4 classes diferentes. Temos então, um problema de multioutput e, portanto Softmax Regression não é aplicável. Para este problema, é necessário utilizar dois algoritmos de Regressão Logística. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
