{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Hadoop-x-RDBMS\" data-toc-modified-id=\"Hadoop-x-RDBMS-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Hadoop x RDBMS</a></span></li><li><span><a href=\"#Cluster\" data-toc-modified-id=\"Cluster-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cluster</a></span><ul class=\"toc-item\"><li><span><a href=\"#Arquitetura-do-Cluster\" data-toc-modified-id=\"Arquitetura-do-Cluster-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Arquitetura do Cluster</a></span></li></ul></li><li><span><a href=\"#Trabalhando-com-Hadoop\" data-toc-modified-id=\"Trabalhando-com-Hadoop-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Trabalhando com Hadoop</a></span></li><li><span><a href=\"#Configuração-Hadoop\" data-toc-modified-id=\"Configuração-Hadoop-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Configuração Hadoop</a></span><ul class=\"toc-item\"><li><span><a href=\"#Modo-Standalone\" data-toc-modified-id=\"Modo-Standalone-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Modo Standalone</a></span></li><li><span><a href=\"#Pseudo-Distribuído\" data-toc-modified-id=\"Pseudo-Distribuído-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Pseudo Distribuído</a></span></li><li><span><a href=\"#Totalmente-Distribuído\" data-toc-modified-id=\"Totalmente-Distribuído-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Totalmente Distribuído</a></span></li></ul></li><li><span><a href=\"#Arquitetura-HDFS\" data-toc-modified-id=\"Arquitetura-HDFS-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Arquitetura HDFS</a></span></li><li><span><a href=\"#Arquitetura-MapReduce\" data-toc-modified-id=\"Arquitetura-MapReduce-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Arquitetura MapReduce</a></span><ul class=\"toc-item\"><li><span><a href=\"#Mapeamento\" data-toc-modified-id=\"Mapeamento-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Mapeamento</a></span></li><li><span><a href=\"#Redução\" data-toc-modified-id=\"Redução-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Redução</a></span></li><li><span><a href=\"#MapReduce\" data-toc-modified-id=\"MapReduce-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>MapReduce</a></span></li></ul></li><li><span><a href=\"#Cache-Distribuído-e-Segurança\" data-toc-modified-id=\"Cache-Distribuído-e-Segurança-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Cache Distribuído e Segurança</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hadoop x RDBMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hadoop não é um Banco de Dados, mas sim um `framework` para armazenamento e processamento de grandes conjuntos de dados. Mas o objetivo não é armazenar dados?\n",
    "\n",
    "Na prática, quando falamos sobre o HDFS, estamos falando, na verdade, de um sistema de arquivos (paralelo ao Windows, Linux), com a diferença do gerenciamento de dados a partir de computadores rodando em um cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\11_hadoop_x_rdbms.png\" alt=\"hadoop_cycle\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conceito de cluster é muito comum na área de tecnologia. O conceito de cluster está relacionado a presença de diversas máquinas funcionando apenas como uma única máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\12_hadoop_cluster.png\" alt=\"hadoop_cycle\" style=\"width:450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada máquina possui seu próprio HD, seu próprio SO, seu próprio processador. Através de um software específico, essas máquinas podem se comportar apenas como uma. Este software é o `Hadoop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitetura do Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\03_hadoop_framework.png\" alt=\"hadoop_fw\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como visto anteriormente, o cluster Hadoop possui dois tipos de nodes:\n",
    "    - Master Node ou Name Node\n",
    "    - Worker (Slave) Node ou Data Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\07_hadoop_hdfsnodes.png\" alt=\"hadoop_hdfsnodes\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando entramos em detalhes sobre tais máquinas, percebemos que cada uma delas pode desempenhar mais de um papel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\13_hadoop_arquitetura_cluster.png\" alt=\"hadoop_cluster\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Master Node**\n",
    "\n",
    "Nele, iremos rodar o serviço que gerencia o `armazenamento` distribuído e também um serviço que gerencia o `processamento` distribuído. Relacionado ao serviço de `JobTracker`\n",
    "\n",
    "* **Slaves**\n",
    "\n",
    "Também irão desempenhar mais de uma função (armazenamento e processamento) através de serviços (`Task Tracker`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\14_hadoop_servicos.png\" alt=\"hadoop_servicos\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\15_cluster_hadoop.png\" alt=\"cluster_hadoop\" style=\"width: 550px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabalhando com Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Passo 1** - Enviar dados ao cluster Hadoop\n",
    "\n",
    "Pode ser feito por diversas maneiras:\n",
    "    - Carga ETL;\n",
    "    - Scoop (ferramenta ETL do Ecossistema Hadoop);\n",
    "    - Dados de um BD (Oracle, SQL);\n",
    "    - Dados de Redes Sociais;\n",
    "    - Arquivos de log de servidores\n",
    "    - Entre outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Passo 2** - Programa de Mapeamento e Redução\n",
    "    - O Cientista de Dados deve desenvolver o programa de MapReduce (Python, Java, Scala, ...)\n",
    "    - O Mapeamento e Redução não é uma solução pronta e precisa ser implementada;\n",
    "    - Disparar o Job no cluster Hadoop;\n",
    "    - Entram em ação o Job Tracker e o Task Tracker\n",
    "    \n",
    "O Job Tracker e o Task Tracker consultam o Name Node:\n",
    "    - \"Quero processar os dados. Onde os dados estão?\"\n",
    "Name Node informa onde estão os blocos de dados para o processamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\16_hadoop_pipeline.png\" alt=\"hadoop_pipeline\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível configurar o Hadoop de acordo com suas necessidades, dentro de três modos diferentes.\n",
    "* **Modo Standalone**\n",
    "* **Pseudo Distribuído**\n",
    "* **Totalmente Distribuío**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modo Standalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste modo, temos um único computador simulando tanto as operações de _master_ como as operações de _slave_. Todos os serviços Hadoop são executados em uma única JVM (Java Virtual Machine) em um mesmo servidor.\n",
    "\n",
    "Mas, pensando na proposta do Hadoop, por que este modo seria útil?\n",
    "\n",
    "A resposta é: `testes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Modo Standalone, é possível simular a operação do Hadoop, em ambiente de desenvolvimento, com uma única máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Distribuído"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os serviços individuais do Hadoop são atribuídos a JVM's individuais, dentro de um mesmo servidor. Neste modo, ainda temos uma única máquina, a exemplo do modo Standalone. Entretanto, temos uma JVM para cada um dos serviços.\n",
    "\n",
    "Se, futuramente, uma JVM apresentar algum tipo de problema, apenas um único serviço será afetado, e não todo o ecossistema montado. Este modo também é aplicável para `testes` e requer uma quantidade maior de memória da máquina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Totalmente Distribuído"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serviços individuais do Hadoop são executados em JVM's individuais, porém dentro do `cluster`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui temos, de fato, o ambiente de produção, de acordo com sua arquitetura."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\17_hadoop_hdfs.png\" alt=\"hadoop_hdfs\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Os serviços de NameNode e Secundary NameNode são os serviços master.\n",
    "    \n",
    "Os serviços `DataNodes` são os slaves. É possível possuir 1 NameNode, 1 Secondary NameNode e uma série grande de DataNodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2 - Jobs que chegam ao serviço Master\n",
    "    \n",
    "O master é responsável por aceitar os Jobs das aplicações clientes e or garantir que os dados requeridos para a aoperação sejam carregados e segregados em pedaços de blocos de dados. O NameNode recebe o `job` e realiza uma \"preparação dos dados\" através dos `arquivos de configuração` (quantidade de blocos no cluster, tamanho de blocos, entre outros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3 - Armazenamento de dados em arquivos\n",
    "\n",
    "O HDFS permite que os dados sejam armazenados em arquivos. Um arquivo é dividido em um ou mais blocos que são armazenados e replicados pelos DataNodes. Os blocos são então distirbuídos para o sistema de DataNodes dentro do cluster. Isso garante que as réplicas de dados sejam mantidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4 - Distribuição das réplicas\n",
    "As réplicas de cada bloco de dados são distribuídas em computadores em todo o cluster, permitindo o acesso de dados confiável e de forma rápida. Tolerância a erros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resumindo**\n",
    "\n",
    "* NameNode recebe as conexões\n",
    "* NameNode consulta o arquivo de configurações (config feita por um Engenheiro de Dados);\n",
    "* Cientista de dados lê o arquivo e descobre o melhor modo de segregar os dados e envia aos DataNodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso do HDFS, temos `serviços` rodando em computadores.\n",
    "    - Namenode (serviço master responsável pelo gerenciamento)\n",
    "    - Datanode (realizam o armazenamento de fato).\n",
    "    \n",
    "No caso do MapReduce, falamos de `processamento`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"images\\18_hadoop_mapreduce.png\" alt=\"hadoop_mapreduce\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\19_hadoop_mr.png\" alt=\"hadoop_mapreduce\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A imagem acima demonstra que, no processamento de MapReduce, dividimos o conjunto de dados em **Listas Ordenadas** (conjunto de chaves e valores) e, posteriormente divido ainda mais esse conjunto. Mas até quando devemos dividir? **Isto é tarefa do Cientista de Dados e depende de cada problema**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No MapReduce, temos basicamente 2 operações:\n",
    "    - Mapeamento\n",
    "    - Redução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapeamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No processo de `mapeamento` (Map), os dados são separados em pares (key-values pairs), transformdos e filtrados. Então, os dados são distribuídos para os nodes e processados. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No processo de `redução` (Reduce), os dados são agregados em conjuntos de dados (datasets) menores. Os dados resultantes do processo de redução são transformados em um formato padrão de chave-valor (key-value), onde a chave (key) funciona como o identificador do registro e o valor (value) é o dado (conteúdo) que é identificado pela chave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images\\20_hadoop_pipe.png\" alt=\"hadoop_mapreduce\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lembrando que:\n",
    "\n",
    "    JobTracker: serviço master do MapReduce\n",
    "    TaskTracker: serviço slave do MapReduce\n",
    "\n",
    "Ambos podem rodar na mesma máquina, contendo:\n",
    "\n",
    "    NameNode: serviço master do HDFS\n",
    "    DataNode: serviço slave do HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1** - Todo o processo se inicia com a requisição feita pelo cliente e o `job` submetido. O JobTracker se encarrega de coordenar como o job será distribuído.\n",
    "\n",
    "**2** - No `mapeamento` dos dados, os dados de entrada são primeiramente distribuídos em pares key-value (definição feita pelo Cientista de Dados ao criar o programa de mapeamento e redução) e divididos em fragmentos, que são atribuídos a tarefas de mapeamento.\n",
    "\n",
    "**3** - No processo de `redução` dos dados, cada operação de redução tem um fragmento atribuído e, então, o processo é executado e o resultado final é gerado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Distribuído e Segurança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Cache Distribuído é uma funcionalidade do Hadoop que permite ganhos consideráveis de performance quando tarefas de map e reduce precisam acessar dados em comum. Permite ainda que um node do cluster acesse os arquivos no sistema de arquivos local, ao invés de solicitar o arquivo em outro node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que você armazena um arquivo em Cache para seu trabalho, a estrutura Hadoop irá torná-lo disponível em cada node (em sistema de arquivos, não em memória) onde as tarefas de mapeamento / redução estão em execução."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segurança**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Hadoop utiliza o `Kerberos`. É necessário configurar a segurança do Hadoop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
